{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imp\n",
    "import scripts as scr\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytictoc import TicToc\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cols (df, dict_col_types = None):\n",
    "    # Расширяйте для необходимых столбцов и их явной типизации\n",
    "    if dict_col_types is None:\n",
    "        dict_col_types = {\n",
    "        'amount_original':(float, 0.0),\n",
    "        'channel_indicator_desc':(str, u'null'),\n",
    "        'event_description':(str, u'null'),\n",
    "        'short_date':(int, 0),\n",
    "        'cdf_s_20':(str, u'null'),\n",
    "        'cdf_s_126':(str, u'null'),\n",
    "        'cdf_s_127':(int, 30),\n",
    "        'cdf_s_129':(int, 30),\n",
    "        'cdf_s_138':(str, u'null'),\n",
    "        'cdf_s_130':(int, 30),\n",
    "        'cdf_s_133':(int, 30),\n",
    "        'cdf_s_134':(int, 30),\n",
    "        'cdf_s_135':(int, 30),\n",
    "        'cdf_s_140':(float, 0.0),\n",
    "        'cdf_s_218':(str, u'null'),\n",
    "        'cdf_s_294':(int, 0),\n",
    "        'cdf_s_299':(str, u'null'),\n",
    "        'data_s_65':(int, 0),\n",
    "        'data_i_120':(int, 0),\n",
    "        'data_i_154':(float, -150)\n",
    "        }\n",
    "                \n",
    "    if df.shape[0] == 0:\n",
    "        return df\n",
    "    \n",
    "    df.replace(u'null', np.nan, inplace=True)\n",
    "\n",
    "    for i in dict_col_types:\n",
    "        if i in df.columns:\n",
    "            change_type, fill_value = dict_col_types[i]\n",
    "            df[i] = df[i].fillna(fill_value).astype(change_type)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calc_base_features(data, is_train):\n",
    "    \n",
    "    def cust_mark_to_class(custom_mark):\n",
    "        \"\"\"\n",
    "        Преобразует входящее значение CUSTOM_MARK в класс\n",
    "        return:\n",
    "            1 - фрод\n",
    "            0 - легитимная\n",
    "            -1 - неизвестно\n",
    "        \"\"\"\n",
    "        ret = -1\n",
    "        if custom_mark in ['F','S']:\n",
    "            ret = 1\n",
    "        elif custom_mark in ['A','G', np.NaN]:\n",
    "            ret = 0\n",
    "\n",
    "        return ret\n",
    "\n",
    "    mobile_cols = ['is_mts', 'is_beeline', 'is_megafon', 'is_tele2', 'is_ru_mobile']\n",
    "    hash_cols = ['hardwareid', 'user_agent_string_hash', 'browser_plugins_hash', 'screen_hash']\n",
    "    hash_cols_fm_names = [f'{x}_notnull' for x in hash_cols]\n",
    "\n",
    "    data = data.merge(ip_df, how = 'left', on = 'ip_address')\n",
    "    data.loc[:, mobile_cols] = data.loc[:, mobile_cols].fillna(-1.0).astype(int)\n",
    "\n",
    "    feat_matrix = pd.DataFrame()\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        return feat_matrix\n",
    "\n",
    "\n",
    "    feat_matrix = pd.DataFrame()\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        raise 'shape is 0'\n",
    "\n",
    "    # заполняем ряд пропусков\n",
    "    data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float) / 1000\n",
    "    data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    feat_matrix['amount'] = data['amount_original']\n",
    "    same_columns = ['event_id', 'user_id', 'event_time', 'short_date', \n",
    "                    'cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135', 'data_i_120']\n",
    "    same_columns += mobile_cols\n",
    "    for column in same_columns:\n",
    "        feat_matrix.loc[:, column] = data[column]\n",
    "    if is_train:\n",
    "        feat_matrix['label'] = [cust_mark_to_class(x) for x in data['custom_mark']]\n",
    "    # ----------\n",
    "    # дополнительные фичи\n",
    "    # по user_id\n",
    "    user_id_what_suffix = pd.Series([re.sub('[0-9]', '', x) for x in data['user_id']])\n",
    "    for suffix in ['MBK', 'VSP', 'CRM', 'IVR', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~user_id_what_suffix.isin(['MBK', 'VSP', 'CRM', 'IVR', '']).astype(int)\n",
    "        else:\n",
    "            result = (user_id_what_suffix == suffix).astype(int)\n",
    "        feat_matrix[f'user_id_{suffix}'] = result\n",
    "    feat_matrix['user_id_digit_only'] = feat_matrix['user_id'].apply(lambda x: x.isdigit()).astype(int)\n",
    "    # по каналу ohe\n",
    "    for suffix in ['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~data.channel_indicator_desc.isin(['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK']).astype(int)\n",
    "        else:\n",
    "            result = (data.channel_indicator_desc == suffix).astype(int)\n",
    "        feat_matrix[f'channel_indicator_desc_is_{suffix}'] = result\n",
    "    # время операции\n",
    "    feat_matrix['event_hour'] = [x.hour for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_hour_night'] = [1 if ((hour >= 23) or (hour <= 7)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_workhour'] = [1 if ((hour >= 8) or (hour <= 17)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_evening'] = [1 if ((hour >= 18) or (hour <= 22)) else 0 for hour in feat_matrix['event_hour']]\n",
    "\n",
    "    feat_matrix['event_day'] = [x.dayofweek for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_day_is_weekend'] = [1 if day >= 6 else 0 for day in feat_matrix['event_day']]\n",
    "    # ----------\n",
    "    # кумулятивная сумма операций за сутки в каналах web и МП, умножил на 1e15 из-за того, что там сильно маленькие числа\n",
    "    feat_matrix['cumulative_sum_total'] = data.cdf_s_140 * 1e15\n",
    "\n",
    "\n",
    "    feat_matrix['client_age'] = [x.days / 365.25 for x in (data.event_time - data.cdf_s_19)]\n",
    "    feat_matrix['client_age_isnull'] = feat_matrix['client_age'].isnull().astype(int)\n",
    "\n",
    "    #заменил на -1\n",
    "    feat_matrix['cat_new_ip'] = [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_126]\n",
    "    feat_matrix['cat_new_prov'] =  [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_138]\n",
    "    feat_matrix['channel_op'] =  [0 if x == 'MOBILE' else 1 if x == 'WEB' else -1 for x in data.channel_indicator_desc]\n",
    "    feat_matrix['op_type'] = [0 if x == 'Перевод частному лицу' else\n",
    "                              1 if x == 'Оплата услуг' else\n",
    "                              2 if x == 'Перевод между своими счетами и картами' else\n",
    "                              3 for x in data.event_description]\n",
    "\n",
    "    # бинарный флаг определяющий наличие возраста получателя\n",
    "    # (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "    feat_matrix['transfer_recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "    # разница возрастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "    feat_matrix['transfer_age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "    feat_matrix.loc[feat_matrix['transfer_age_diff'] < 0, 'transfer_age_diff'] = -999\n",
    "    # перевод родственнику\n",
    "    feat_matrix['transfer_for_relative'] = [1 if x == 'ДА' else 0 for x in data.cdf_s_218] \n",
    "    # сила связи отправителя и получателя\n",
    "    feat_matrix['transfer_know_recip_squared'] = [ x if x is not None else 0 for x in data.data_s_65]\n",
    "    # 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    "    feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "    # 'cdf_s_124'- дата выдачи карты получателя\n",
    "    feat_matrix['know_recip_card_age'] = ~data.cdf_s_124.isnull().astype(int)\n",
    "    # в cdf_s_124 подмешана дата рождения, поэтому и max\n",
    "    feat_matrix['recip_card_age'] = [max(x.days, 1000) if type(x) is not pd.tslib.NaTType else 1000 \n",
    "                                     for x in (data.event_time - data.cdf_s_124)]\n",
    "\n",
    "    feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "\n",
    "    # там с провайдером какая-то фигня до этого была (использовалась левая переменная)\n",
    "    feat_matrix['ip_isp'] = data['ip_isp'].fillna(-1000000).astype(int)\n",
    "\n",
    "    #ADD NEW FEATURES\n",
    "    # natural log of amount\n",
    "    feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "\n",
    "    # len and code of region name\n",
    "    feat_matrix['client_region_len'] = data.cdf_s_20.apply(lambda x: len(str(x)))\n",
    "    feat_matrix['client_region'] = np.array([x if x.isdigit() else -1 for x in data.cdf_s_20], dtype=float)\n",
    "\n",
    "    # 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП \n",
    "    feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0) / \\\n",
    "                                 (data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "                                  data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "                                  data[\"cdf_s_140\"].fillna(0).astype(float) + 1))\n",
    "\n",
    "    # добавил флаги стран по ip адресам\n",
    "\n",
    "    top_countries = np.array(['ru', 'kz', 'ua', 'br', 'tr', 'th'])\n",
    "    country_names = [f'ip_contry_{x}' for x in top_countries.tolist() + ['null', 'is_unknown', 'is_other']]\n",
    "\n",
    "    def parse_ip_country(x):\n",
    "        result = np.zeros(len(country_names), dtype = int)\n",
    "        if x is np.nan:\n",
    "            result[-3] = 1\n",
    "        elif x in top_countries:\n",
    "            result[np.argmax(top_countries == x)] = 1\n",
    "        elif x in ['++', '??']:\n",
    "            result[-2] = 1\n",
    "        else:\n",
    "            result[-1] = 1\n",
    "        return result\n",
    "    temp = data['ip_country'].apply(parse_ip_country)\n",
    "\n",
    "    for n, col in enumerate(country_names):\n",
    "        feat_matrix[col] = [x[n] for x in temp]\n",
    "\n",
    "    # флаг null / not null по ['hardwareid', 'user_agent_string_hash', 'browser_plugins_hash', 'screen_hash']\n",
    "\n",
    "    for fm_name, col in zip(hash_cols_fm_names, hash_cols):\n",
    "        feat_matrix[fm_name] = data[col].isnull().astype(int)\n",
    "\n",
    "    # поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "    order_cols = ['event_id', 'user_id', 'label', 'event_time', 'short_date', 'amount',\n",
    "                  'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
    "                  'cumulative_sum_total', 'data_i_120', 'data_i_154', \n",
    "                  'cdf_s_127', 'cdf_s_129','cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135',\n",
    "                  'know_recip_card_age', 'recip_card_age', 'one_region', \n",
    "                  'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "    order_cols += mobile_cols + country_names + hash_cols_fm_names\n",
    "    order_cols += [x for x in feat_matrix.columns if not x in order_cols] # все остальные\n",
    "    if not is_train:\n",
    "        order_cols.remove('label')\n",
    "    return feat_matrix[order_cols]\n",
    "\n",
    "\n",
    "def get_data(chunk_name, is_train = True):\n",
    "    \n",
    "    def load_data(chunk_fnames, fields=None, query=None, sample='train', dict_col_types=None):\n",
    "        df = pd.DataFrame({})\n",
    "        if isinstance(chunk_fnames, str):\n",
    "            chunk_fnames = [chunk_fnames]\n",
    "\n",
    "        for filename in chunk_fnames:\n",
    "            chunk_df = pd.read_feather(filename)\n",
    "\n",
    "            if fields is None:\n",
    "                fields = chunk_df.columns.tolist()\n",
    "\n",
    "            transormed = transform_cols(chunk_df)\n",
    "\n",
    "            if query:\n",
    "                transormed = transormed.query(query)\n",
    "\n",
    "            df = pd.concat([df, transormed[fields]], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def features_handler(chunk_name, calc_feat, query=None):\n",
    "\n",
    "        loaded_data = load_data(chunk_name, query=query, dict_col_types=None)\n",
    "        res_df = calc_feat(loaded_data, is_train = is_train)\n",
    "\n",
    "        return res_df\n",
    "\n",
    "\n",
    "    feat_test = features_handler(\n",
    "        query = query,\n",
    "        chunk_name = chunk_name,\n",
    "        calc_feat = calc_base_features)\n",
    "    return feat_test\n",
    "\n",
    "def get_data_test(chunk_name):\n",
    "    return get_data(chunk_name, is_train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_df = pd.read_pickle('../../data/ip_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_address</th>\n",
       "      <th>is_mts</th>\n",
       "      <th>is_beeline</th>\n",
       "      <th>is_megafon</th>\n",
       "      <th>is_tele2</th>\n",
       "      <th>is_ru_mobile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.173.86.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.173.82.117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.173.85.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.173.82.110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.173.81.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ip_address  is_mts  is_beeline  is_megafon  is_tele2  is_ru_mobile\n",
       "0    31.173.86.8       0           0           1         0             1\n",
       "1  31.173.82.117       0           0           1         0             1\n",
       "2  31.173.85.200       0           0           1         0             1\n",
       "3  31.173.82.110       0           0           1         0             1\n",
       "4   31.173.81.68       0           0           1         0             1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files is 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/train/chunk_0.fth',\n",
       " '../../data/raw_splits/train/chunk_1.fth',\n",
       " '../../data/raw_splits/train/chunk_2.fth',\n",
       " '../../data/raw_splits/train/chunk_3.fth',\n",
       " '../../data/raw_splits/train/chunk_4.fth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_N = 100\n",
    "N_THREADS = 16\n",
    "train_folder = '../../data/raw_splits/train/'\n",
    "train_files = sorted([x for x in os.listdir(train_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "train_files = [os.path.join(train_folder, x) for x in train_files]\n",
    "print(f'Length of train files is {len(train_files)}')\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test files is 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/test/chunk_0.fth',\n",
       " '../../data/raw_splits/test/chunk_1.fth',\n",
       " '../../data/raw_splits/test/chunk_2.fth',\n",
       " '../../data/raw_splits/test/chunk_3.fth',\n",
       " '../../data/raw_splits/test/chunk_4.fth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder = '../../data/raw_splits/test/'\n",
    "test_files = sorted([x for x in os.listdir(test_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "test_files = [os.path.join(test_folder, x) for x in test_files]\n",
    "print(f'Length of test files is {len(test_files)}')\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p '../../data/prepaired_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"event_description in ('Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами') and short_date >= 20171029 and short_date <= 20171128\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_channels = ['Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами']\n",
    "\n",
    "start_date = 20171029\n",
    "end_date = 20171128\n",
    "\n",
    "query = f\"event_description in ({str(include_channels)[1:-1]})\" + \\\n",
    "        f\" and short_date >= {str(start_date)}\" + \\\n",
    "        f\" and short_date <= {str(end_date)}\"\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.84 s, sys: 5.99 s, total: 8.83 s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# жрет вплоть более 70 гигов оперативки, осторожнее\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "        results = pool.map(get_data, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    3802643\n",
       " 1      14012\n",
       "-1       3664\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3820319, 68)\n",
      "CPU times: user 4.03 s, sys: 8.69 s, total: 12.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_df = pd.concat(results).reset_index().drop('index', axis = 1)\n",
    "display(total_df['label'].value_counts())\n",
    "print(total_df.shape)\n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df.to_feather('../../data/prepaired_dataset/train_v3.fth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 5.12 s, total: 6.27 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# жрет вплоть более 70 гигов оперативки, осторожнее\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "        results = pool.map(get_data_test, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2035724, 67)\n",
      "CPU times: user 2.31 s, sys: 4.64 s, total: 6.95 s\n",
      "Wall time: 6.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_df = pd.concat(results).reset_index().drop('index', axis = 1)\n",
    "print(total_df.shape)\n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df.to_feather('../../data/prepaired_dataset/test_v3.fth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pytictoc\n",
    "import multiprocessing\n",
    "from collections import defaultdict, OrderedDict\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "prequants = pd.read_csv(\"../../data/coms_sep/quantiles_data/for_quantiles.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants['short_date'] = pd.to_datetime(prequants['event_time']).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "prequants.drop('event_time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['ATMAPI', 'MBK', 'MOBILEAPI', 'UFS', 'WEBAPI', 'amount_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants = pd.get_dummies(prequants, columns=['channel_indicator_desc'], prefix=\"\", prefix_sep=\"\")\n",
    "prequants.rename(columns={'UFS.WEBAPI': 'UFS'}, inplace=True)\n",
    "\n",
    "for i in channels[:-1]:\n",
    "    prequants[i] = (prequants[\"amount_original\"] * prequants[i]).astype(int)\n",
    "prequants[\"amount_original\"] = prequants[\"amount_original\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 days, amount + channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#говнокод\n",
    "dates_big_list = \\\n",
    "[int(f'201710%0.2d' % x) for x in list(range(28, 32))] + \\\n",
    "[int(f'201711%0.2d' % x) for x in list(range(1, 31))] + \\\n",
    "[int(f'201712%0.2d' % x) for x in list(range(1, 6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quants_per_channel(channel):\n",
    "    df = prequants[['user_id', 'short_date', channel]].copy()\n",
    "    df = df.query(f\"{channel} != 0\")\n",
    "    \n",
    "    quants_range = np.arange(0.1, 1.1, 0.1)\n",
    "    NDAYS = 30 # за какой временной промежуток берем медиану\n",
    "    quants_names = ['%s_%s_days_quantile_%0.1f' % (channel, NDAYS, q) for q in quants_range]\n",
    "    \n",
    "    \n",
    "    grouper = itertools.groupby(zip(df['user_id'], df['short_date'], df[channel]), key = lambda x: x[0])\n",
    "    grouping_result = defaultdict(dict)\n",
    "    for uid, values in tqdm_notebook(grouper, total = df['user_id'].nunique()):\n",
    "        (_, dates, amounts) = zip(*values)\n",
    "        date_amount_dict = defaultdict(list)\n",
    "        # сначала сделаем dict из даты в качестве ключа и amount каждой транзакции пользователя за этот день\n",
    "        for date, amount_iter in itertools.groupby(zip(dates, amounts), key = lambda x: x[0]):\n",
    "            _, day_amount_list = list(zip(*amount_iter))\n",
    "            date_amount_dict[date] = day_amount_list\n",
    "        # при правке интервалов даты поправить STARTING_NDAY, NDAYS\n",
    "        for n in range(len(dates_big_list)):\n",
    "            calculating_dates = dates_big_list[n - NDAYS: n]\n",
    "            calculating_list = list(itertools.chain.from_iterable((date_amount_dict[x] for x in calculating_dates)))\n",
    "            calc_quantile = lambda q: np.percentile(calculating_list, q * 100) if len(calculating_list) else 0\n",
    "            quantiles = [calc_quantile(q) for q in quants_range]\n",
    "            grouping_result[uid][dates_big_list[n]] = quantiles\n",
    "    \n",
    "    df_grouped_list = [[(uid, date, *quantiles) for date, quantiles in date_dict.items()] \\\n",
    "                       for uid, date_dict in grouping_result.items()]\n",
    "    df_grouped = pd.DataFrame(list(itertools.chain.from_iterable(df_grouped_list)), \n",
    "                              columns = ['user_id', 'short_date'] + quants_names)\n",
    "    df_grouped.to_csv(\"../../data/coms_sep/quantiles_data/qnts_train_30_{}.csv\".format(channel))\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 1.53 s, sys: 540 ms, total: 2.07 s\n",
      "Wall time: 34min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['OK', 'OK', 'OK', 'OK', 'OK', 'OK']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "(Parallel(n_jobs=6)(delayed(quants_per_channel)(channel)\n",
    "                    for channel in channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90 days, amount_original\n",
    "#### не делаем, потому что в тесте нет столько истории"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 days channels+amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test files is 26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "FIRST_N = 100\n",
    "N_THREADS = 5\n",
    "test_folder = '../../data/raw_splits/test/'\n",
    "test_files = sorted([x for x in os.listdir(test_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "test_files = [os.path.join(test_folder, x) for x in test_files]\n",
    "print(f'Length of test files is {len(test_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#говнокод\n",
    "dates_big_list = \\\n",
    "[int(f'201711%0.2d' % x) for x in list(range(29, 31))] + \\\n",
    "[int(f'201712%0.2d' % x) for x in list(range(1, 6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20171129, 20171130, 20171201, 20171202, 20171203, 20171204, 20171205]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_big_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(chunk_name):\n",
    "    chunk_df = pd.read_feather(chunk_name)[['user_id', 'event_time',\n",
    "                                           'amount_original',\n",
    "                                           'channel_indicator_desc']]\n",
    "    return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 5.26 s, total: 8.64 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features matrix\n",
    "with multiprocessing.Pool(processes=5) as pool:\n",
    "    results = pool.map(get_data, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants = pd.DataFrame()\n",
    "for i, df in enumerate(results):\n",
    "    prequants = pd.concat([prequants, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants = prequants.loc[np.logical_not(np.isnan(prequants['amount_original']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants.to_csv(\"../../data/coms_sep/for_quantiles_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants['short_date'] = pd.to_datetime(prequants['event_time']).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "prequants.drop('event_time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20171007, 20171205)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prequants.short_date.min(), prequants.short_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train channels = ['ATMAPI', 'MBK', 'MOBILEAPI', 'UFS.WEBAPI', 'WEBAPI']\n",
    "<br>\n",
    "unexpected in test = ['CALLCENTER', 'CRM', 'IVR', 'VSP',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['ATMAPI', 'MBK', 'MOBILEAPI', 'UFS', 'WEBAPI', 'amount_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants = pd.get_dummies(prequants, columns=['channel_indicator_desc'], prefix=\"\", prefix_sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "prequants.rename(columns={'UFS.WEBAPI': 'UFS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in channels[:-1]:\n",
    "    prequants[i] = (prequants[\"amount_original\"] * prequants[i]).astype(int)\n",
    "prequants[\"amount_original\"] = prequants[\"amount_original\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quants_per_channel(channel):\n",
    "    df = prequants[['user_id', 'short_date', channel]].copy()\n",
    "    df = df.query(f\"{channel} != 0\")\n",
    "    \n",
    "    quants_range = np.arange(0.1, 1.1, 0.1)\n",
    "    NDAYS = 30 # за какой временной промежуток берем квантили\n",
    "    quants_names = ['%s_%s_days_quantile_%0.1f' % (channel, NDAYS, q) for q in quants_range]\n",
    "    # assert STARTING_NDAY >= NDAYS\n",
    "    \n",
    "    \n",
    "    \n",
    "    grouper = itertools.groupby(zip(df['user_id'], df['short_date'], df[channel]), key = lambda x: x[0])\n",
    "    grouping_result = defaultdict(dict)\n",
    "    for uid, values in tqdm_notebook(grouper, total = df['user_id'].nunique()):\n",
    "        (_, dates, amounts) = zip(*values)\n",
    "        date_amount_dict = defaultdict(list)\n",
    "        # сначала сделаем dict из даты в качестве ключа и amount каждой транзакции пользователя за этот день\n",
    "        for date, amount_iter in itertools.groupby(zip(dates, amounts), key = lambda x: x[0]):\n",
    "            _, day_amount_list = list(zip(*amount_iter))\n",
    "            date_amount_dict[date] = day_amount_list\n",
    "        # при правке интервалов даты поправить STARTING_NDAY, NDAYS\n",
    "        for n in range(len(dates_big_list)):\n",
    "            calculating_dates = dates_big_list[n - NDAYS: n]\n",
    "            calculating_list = list(itertools.chain.from_iterable((date_amount_dict[x] for x in calculating_dates)))\n",
    "            calc_quantile = lambda q: np.percentile(calculating_list, q * 100) if len(calculating_list) else 0\n",
    "            quantiles = [calc_quantile(q) for q in quants_range]\n",
    "            grouping_result[uid][dates_big_list[n]] = quantiles\n",
    "    \n",
    "    df_grouped_list = [[(uid, date, *quantiles) for date, quantiles in date_dict.items()] \\\n",
    "                       for uid, date_dict in grouping_result.items()]\n",
    "    df_grouped = pd.DataFrame(list(itertools.chain.from_iterable(df_grouped_list)), \n",
    "                              columns = ['user_id', 'short_date'] + quants_names)\n",
    "    # поменял на test ----\n",
    "    df_grouped.to_csv(\"../../data/coms_sep/quantiles_data/qnts_test_30_{}.csv\".format(channel))\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 1.58 s, sys: 1.56 s, total: 3.14 s\n",
      "Wall time: 8min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['OK', 'OK', 'OK', 'OK', 'OK', 'OK']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "(Parallel(n_jobs=6)(delayed(quants_per_channel)(channel)\n",
    "                    for channel in channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

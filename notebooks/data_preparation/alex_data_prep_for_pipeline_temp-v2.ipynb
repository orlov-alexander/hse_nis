{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imp\n",
    "import scripts as scr\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytictoc import TicToc\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cols (df, dict_col_types = None):\n",
    "    # Расширяйте для необходимых столбцов и их явной типизации\n",
    "    if dict_col_types is None:\n",
    "        dict_col_types = {\n",
    "        'amount_original':(float, 0.0),\n",
    "        'channel_indicator_desc':(str, u'null'),\n",
    "        'event_description':(str, u'null'),\n",
    "        'short_date':(int, 0),\n",
    "        'cdf_s_20':(str, u'null'),\n",
    "        'cdf_s_126':(str, u'null'),\n",
    "        'cdf_s_127':(int, 30),\n",
    "        'cdf_s_129':(int, 30),\n",
    "        'cdf_s_138':(str, u'null'),\n",
    "        'cdf_s_130':(int, 30),\n",
    "        'cdf_s_133':(int, 30),\n",
    "        'cdf_s_134':(int, 30),\n",
    "        'cdf_s_135':(int, 30),\n",
    "        'cdf_s_140':(float, 0.0),\n",
    "        'cdf_s_218':(str, u'null'),\n",
    "        'cdf_s_294':(int, 0),\n",
    "        'cdf_s_299':(str, u'null'),\n",
    "        'data_s_65':(int, 0),\n",
    "        'data_i_120':(int, 0),\n",
    "        'data_i_154':(float, -150)\n",
    "        }\n",
    "                \n",
    "    if df.shape[0] == 0:\n",
    "        return df\n",
    "    \n",
    "    df.replace(u'null', np.nan, inplace=True)\n",
    "\n",
    "    for i in dict_col_types:\n",
    "        if i in df.columns:\n",
    "            change_type, fill_value = dict_col_types[i]\n",
    "            df[i] = df[i].fillna(fill_value).astype(change_type)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calc_base_features(data):\n",
    "    \n",
    "    def cust_mark_to_class(custom_mark):\n",
    "        \"\"\"\n",
    "        Преобразует входящее значение CUSTOM_MARK в класс\n",
    "        return:\n",
    "            1 - фрод\n",
    "            0 - легитимная\n",
    "            -1 - неизвестно\n",
    "        \"\"\"\n",
    "        ret = -1\n",
    "        if custom_mark in ['F','S']:\n",
    "            ret = 1\n",
    "        elif custom_mark in ['A','G', np.NaN]:\n",
    "            ret = 0\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    feat_matrix = pd.DataFrame()\n",
    "    \n",
    "    if data.shape[0] == 0:\n",
    "        return feat_matrix\n",
    "    \n",
    "\n",
    "    feat_matrix = pd.DataFrame()\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        raise 'shape is 0'\n",
    "\n",
    "    # заполняем ряд пропусков\n",
    "    data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float) / 1000\n",
    "    data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    feat_matrix['amount'] = data['amount_original']\n",
    "    same_columns = ['event_id', 'user_id', 'event_time', 'short_date', \n",
    "                    'cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135', 'data_i_120']\n",
    "    for column in same_columns:\n",
    "        feat_matrix.loc[:, column] = data[column]\n",
    "    feat_matrix['label'] = [cust_mark_to_class(x) for x in data['custom_mark']]\n",
    "    # ----------\n",
    "    # дополнительные фичи\n",
    "    # по user_id\n",
    "    user_id_what_suffix = pd.Series([re.sub('[0-9]', '', x) for x in data['user_id']])\n",
    "    for suffix in ['MBK', 'VSP', 'CRM', 'IVR', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~user_id_what_suffix.isin(['MBK', 'VSP', 'CRM', 'IVR', '']).astype(int)\n",
    "        else:\n",
    "            result = (user_id_what_suffix == suffix).astype(int)\n",
    "        feat_matrix[f'user_id_{suffix}'] = result\n",
    "    feat_matrix['user_id_digit_only'] = feat_matrix['user_id'].apply(lambda x: x.isdigit()).astype(int)\n",
    "    # по каналу ohe\n",
    "    for suffix in ['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~data.channel_indicator_desc.isin(['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK']).astype(int)\n",
    "        else:\n",
    "            result = (data.channel_indicator_desc == suffix).astype(int)\n",
    "        feat_matrix[f'channel_indicator_desc_is_{suffix}'] = result\n",
    "    # время операции\n",
    "    feat_matrix['event_hour'] = [x.hour for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_hour_night'] = [1 if ((hour >= 23) or (hour <= 7)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_workhour'] = [1 if ((hour >= 8) or (hour <= 17)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_evening'] = [1 if ((hour >= 18) or (hour <= 22)) else 0 for hour in feat_matrix['event_hour']]\n",
    "        \n",
    "    feat_matrix['event_day'] = [x.dayofweek for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_day_is_weekend'] = [1 if day >= 6 else 0 for day in feat_matrix['event_day']]\n",
    "    # ----------\n",
    "    # кумулятивная сумма операций за сутки в каналах web и МП, умножил на 1e15 из-за того, что там сильно маленькие числа\n",
    "    feat_matrix['cumulative_sum_total'] = data.cdf_s_140 * 1e15\n",
    "\n",
    "\n",
    "    feat_matrix['client_age'] = [x.days / 365.25 for x in (data.event_time - data.cdf_s_19)]\n",
    "    feat_matrix['client_age_isnull'] = feat_matrix['client_age'].isnull().astype(int)\n",
    "\n",
    "    #заменил на -1\n",
    "    feat_matrix['cat_new_ip'] = [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_126]\n",
    "    feat_matrix['cat_new_prov'] =  [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_138]\n",
    "    feat_matrix['channel_op'] =  [0 if x == 'MOBILE' else 1 if x == 'WEB' else -1 for x in data.channel_indicator_desc]\n",
    "    feat_matrix['op_type'] = [0 if x == 'Перевод частному лицу' else\n",
    "                              1 if x == 'Оплата услуг' else\n",
    "                              2 if x == 'Перевод между своими счетами и картами' else\n",
    "                              3 for x in data.event_description]\n",
    "\n",
    "    # бинарный флаг определяющий наличие возраста получателя\n",
    "    # (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "    feat_matrix['transfer_recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "    # разница возрастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "    feat_matrix['transfer_age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "    feat_matrix.loc[feat_matrix['transfer_age_diff'] < 0, 'transfer_age_diff'] = -999\n",
    "    # перевод родственнику\n",
    "    feat_matrix['transfer_for_relative'] = [1 if x == 'ДА' else 0 for x in data.cdf_s_218] \n",
    "    # сила связи отправителя и получателя\n",
    "    feat_matrix['transfer_know_recip_squared'] = [ x if x is not None else 0 for x in data.data_s_65]\n",
    "    # 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    "    feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "    # 'cdf_s_124'- дата выдачи карты получателя\n",
    "    feat_matrix['know_recip_card_age'] = ~data.cdf_s_124.isnull().astype(int)\n",
    "    # в cdf_s_124 подмешана дата рождения, поэтому и max\n",
    "    feat_matrix['recip_card_age'] = [max(x.days, 1000) if type(x) is not pd.tslib.NaTType else 1000 \n",
    "                                     for x in (data.event_time - data.cdf_s_124)]\n",
    "\n",
    "    feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "\n",
    "    # там с провайдером какая-то фигня до этого была (использовалась левая переменная)\n",
    "    feat_matrix['ip_isp'] = data['ip_isp'].fillna(-1000000).astype(int)\n",
    "    \n",
    "    #ADD NEW FEATURES\n",
    "    # natural log of amount\n",
    "    feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "\n",
    "    # len and code of region name\n",
    "    feat_matrix['client_region_len'] = data.cdf_s_20.apply(lambda x: len(str(x)))\n",
    "    feat_matrix['client_region'] = np.array([x if x.isdigit() else -1 for x in data.cdf_s_20], dtype=float)\n",
    "    \n",
    "    # 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП \n",
    "    feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0) / \\\n",
    "                                 (data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "                                  data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "                                  data[\"cdf_s_140\"].fillna(0).astype(float) + 1))\n",
    "\n",
    "    # поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "    order_cols = ['event_id', 'user_id', 'label', 'event_time', 'short_date', 'amount',\n",
    "                  'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
    "                  'cumulative_sum_total', 'data_i_120', 'data_i_154', \n",
    "                  'cdf_s_127', 'cdf_s_129','cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135',\n",
    "                  'know_recip_card_age', 'recip_card_age', 'one_region', \n",
    "                  'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "    order_cols += [x for x in feat_matrix.columns if not x in order_cols] # все остальные\n",
    "    return feat_matrix[order_cols]\n",
    "\n",
    "\n",
    "def get_data(chunk_name):\n",
    "    \n",
    "    def load_data(chunk_fnames, fields=None, query=None, sample='train', dict_col_types=None):\n",
    "        df = pd.DataFrame({})\n",
    "        if isinstance(chunk_fnames, str):\n",
    "            chunk_fnames = [chunk_fnames]\n",
    "\n",
    "        for filename in chunk_fnames:\n",
    "            chunk_df = pd.read_feather(filename)\n",
    "\n",
    "            if fields is None:\n",
    "                fields = chunk_df.columns.tolist()\n",
    "\n",
    "            transormed = transform_cols(chunk_df)\n",
    "\n",
    "            if query:\n",
    "                transormed = transormed.query(query)\n",
    "\n",
    "            df = pd.concat([df, transormed[fields]], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def features_handler(chunk_names, calc_feat, query=None, chunk_size=5000):\n",
    "        res_df = pd.DataFrame()\n",
    "\n",
    "        for chunk_name in chunk_names:\n",
    "            loaded_data = load_data(chunk_name, query=query, dict_col_types=None)\n",
    "            feat_chunk = calc_feat(loaded_data)\n",
    "            res_df = pd.concat([res_df, feat_chunk], ignore_index=True)\n",
    "\n",
    "        return res_df\n",
    "\n",
    "\n",
    "    feat_test = features_handler(\n",
    "        query = query,\n",
    "        chunk_names=[chunk_name],\n",
    "        calc_feat = calc_base_features)\n",
    "    return feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files is 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/train/chunk_0.fth',\n",
       " '../../data/raw_splits/train/chunk_1.fth',\n",
       " '../../data/raw_splits/train/chunk_2.fth',\n",
       " '../../data/raw_splits/train/chunk_3.fth',\n",
       " '../../data/raw_splits/train/chunk_4.fth']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_N = 100\n",
    "N_THREADS = 16\n",
    "train_folder = '../../data/raw_splits/train/'\n",
    "train_files = sorted([x for x in os.listdir(train_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "train_files = [os.path.join(train_folder, x) for x in train_files]\n",
    "print(f'Length of train files is {len(train_files)}')\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"event_description in ('Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами') and short_date >= 20171029 and short_date <= 20171128\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_channels = ['Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами']\n",
    "\n",
    "start_date = 20171029\n",
    "end_date = 20171128\n",
    "\n",
    "query = f\"event_description in ({str(include_channels)[1:-1]})\" + \\\n",
    "        f\" and short_date >= {str(start_date)}\" + \\\n",
    "        f\" and short_date <= {str(end_date)}\"\n",
    "query"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "test_feats = get_data(train_files[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 4.55 s, total: 7.45 s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# жрет вплоть более 70 гигов оперативки, осторожнее\n",
    "with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "    results = pool.map(get_data, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df = pd.DataFrame()\n",
    "# for i, df in tqdm_notebook(enumerate(results), total = len(results)):\n",
    "total_df = pd.concat(total_df).reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    3802643\n",
       " 1      14012\n",
       "-1       3664\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3820319, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'user_id', 'label', 'event_time', 'short_date', 'amount',\n",
       "       'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
       "       'cumulative_sum_total', 'data_i_120', 'data_i_154', 'cdf_s_127',\n",
       "       'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135',\n",
       "       'know_recip_card_age', 'recip_card_age', 'one_region', 'log_amount',\n",
       "       'ip_isp', 'amnt2chnls', 'user_id_MBK', 'user_id_VSP', 'user_id_CRM',\n",
       "       'user_id_IVR', 'user_id_other', 'user_id_digit_only',\n",
       "       'channel_indicator_desc_is_MOBILEAPI',\n",
       "       'channel_indicator_desc_is_WEBAPI', 'channel_indicator_desc_is_ATMAPI',\n",
       "       'channel_indicator_desc_is_MBK', 'channel_indicator_desc_is_other',\n",
       "       'event_hour', 'event_hour_night', 'event_hour_workhour',\n",
       "       'event_hour_evening', 'event_day', 'event_day_is_weekend',\n",
       "       'client_age_isnull', 'transfer_recip_age', 'transfer_age_diff',\n",
       "       'transfer_for_relative', 'transfer_know_recip_squared',\n",
       "       'client_region_len', 'client_region'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(total_df.shape)\n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p '../../data/prepaired_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_feather('../../data/prepaired_dataset/train_v2.fth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

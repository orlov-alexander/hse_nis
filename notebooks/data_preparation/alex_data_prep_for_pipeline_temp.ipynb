{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imp\n",
    "import scripts as scr\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import datetime\n",
    "\n",
    "\n",
    "def transform_cols (df, dict_col_types = None):\n",
    "    # Расширяйте для необходимых столбцов и их явной типизации\n",
    "    if dict_col_types is None:\n",
    "        dict_col_types = {\n",
    "        'amount_original':(float, 0.0),\n",
    "        'cdf_s_126':(str, u'null'),\n",
    "        'cdf_s_138':(str, u'null'),\n",
    "        'channel_indicator_desc':(str, u'null'),\n",
    "        'event_description':(str, u'null'),\n",
    "        'cdf_s_294':(int, 0),\n",
    "        'cdf_s_140':(float, 0.0),\n",
    "        'data_i_120':(int, 0),\n",
    "        'cdf_s_218':(str, u'null'),\n",
    "        'data_s_65':(int, 0),\n",
    "        'cdf_s_127':(int, 30),\n",
    "        'cdf_s_135':(int, 30),\n",
    "        'cdf_s_130':(int, 30),\n",
    "        'cdf_s_129':(int, 30),\n",
    "        'cdf_s_134':(int, 30),\n",
    "        'data_i_154':(float, -150),\n",
    "        'cdf_s_133':(int, 30),\n",
    "        'cdf_s_20':(str, u'null'),\n",
    "        'cdf_s_299':(str, u'null'),\n",
    "        'short_date':(int, 0)\n",
    "        }\n",
    "                \n",
    "    if df.shape[0] > 0:\n",
    "        df.replace(u'null', np.nan, inplace=True)\n",
    "\n",
    "        for i in dict_col_types:\n",
    "            if i in df.columns:\n",
    "                df[i] = df[i].fillna(dict_col_types[i][1]).astype(dict_col_types[i][0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calc_base_features(data):\n",
    "    feat_matrix = pd.DataFrame()\n",
    "    #data = data[data.event_description.isin([u'Перевод частному лицу',u'Оплата услуг',u'Перевод между своими счетами и картами'])]\n",
    "    \n",
    "    if data.shape[0] == 0:\n",
    "        return feat_matrix\n",
    "    \n",
    "    # заполняем ряд пропусков\n",
    "    data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float)/1000 # кумулятивная сумма опреаций за сутки, если не заполнена, то значит это первая операций, т.е. = 0\n",
    "    data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    \n",
    "    feat_matrix['event_id'] = data.event_id\n",
    "    feat_matrix['user_id'] = data.user_id\n",
    "\n",
    "    feat_matrix['custom_mark'] = data.custom_mark    \n",
    "    feat_matrix['event_time'] = data.event_time\n",
    "\n",
    "    feat_matrix['amount'] = data.amount_original\n",
    "    \n",
    "    feat_matrix['client_age'] = [x.days/360 for x in (data.event_time - data.cdf_s_19)]\n",
    "  \n",
    "        \n",
    "    feat_matrix['cat_new_ip'] = [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_126]\n",
    "    feat_matrix['cat_new_prov'] =  [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_138]\n",
    "    feat_matrix['channel_op'] =  [0 if x == u'MOBILE' else 1 if x == u'WEB' else 2 for x in data.channel_indicator_desc]\n",
    "    feat_matrix['op_type'] = [0 if x == u'Перевод частному лицу' else 1 if x==u'Оплата услуг' else 2 if x ==u'Перевод между своими счетами и картами' else 3 for x in data.event_description]\n",
    "\n",
    "\n",
    "    feat_matrix ['recip_age'] =  [1 if x == 0 else 0 for x in data.cdf_s_294] # бинарный флаг определяющий наличие возраста получателя (полезен для линейных моделей, менее для деревьев с учетом следующего признака)\n",
    "    \n",
    "    feat_matrix['age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294] # разница возорастов получателей и отправителей, если отсутствует/неприменимо, то padding 500    \n",
    "  \n",
    "    \n",
    "    feat_matrix['cumulative_sum_total'] = data.cdf_s_140 # кумулятивная сумма операций за сутки в каналах web и МП\n",
    "    \n",
    "    feat_matrix['data_i_120'] = data.data_i_120 \n",
    "    \n",
    "    \n",
    "    feat_matrix['relative'] = [1 if x == u'ДА' else 0 for x in data.cdf_s_218] # перевод родственнику\n",
    "    \n",
    "    feat_matrix['know_recip_power'] = [ x if x is not None else 0 for x in data.data_s_65] # сила связи отправителя и получателя\n",
    "    \n",
    "\n",
    "    feat_matrix['cdf_s_127'] = data.cdf_s_127#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['cdf_s_135'] = data.cdf_s_135#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['cdf_s_130'] = data.cdf_s_130#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['cdf_s_129'] = data.cdf_s_129#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['cdf_s_134'] = data.cdf_s_134#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "    feat_matrix['cdf_s_133'] = data.cdf_s_133#.apply(lambda x: 1 if x is not None else 0)\n",
    "    feat_matrix['data_i_120'] = data.data_i_120\n",
    "    feat_matrix['know_recip_card_age'] = [1 if x is not None else 0 for x in data.cdf_s_124]\n",
    "    \n",
    "    \n",
    "    feat_matrix['recip_card_age'] = [x.days if type(x) is not pd.tslib.NaTType else 912321 for x in (data.event_time - data.cdf_s_124)]\n",
    "    \n",
    "    # feat_matrix['cat_client_region'] = [x if x.isdigit() else 912321 for x in data.cdf_s_20]\n",
    "    feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "    \n",
    "\n",
    "    #ADD NEW FEATURES\n",
    "    feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "    feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "    feat_matrix['ip_isp'] = np.array([x if x.isdigit() else 912321 for x in data.cdf_s_20], dtype=float)\n",
    "    feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0).astype(float) / \\\n",
    "        (data[\"cdf_s_136\"].fillna(0).astype(float) + data[\"amount_original\"].fillna(0).astype(float) + \\\n",
    "            data[\"amount_original\"].fillna(0) + 1))\n",
    "    return feat_matrix\n",
    "\n",
    "\n",
    "def load_data(chunk_fnames, fields=None, query=None, sample='train', dict_col_types=None):\n",
    "    df = pd.DataFrame({})\n",
    "    \n",
    "    if not isinstance(chunk_names, list):\n",
    "        chunk_names = [chunk_names]\n",
    "        \n",
    "    for filename in chunkf_names:\n",
    "        chunk_df = pd.read_feather(filename)\n",
    "            \n",
    "        if fields is None:\n",
    "            fields = chunk_df.columns.tolist()\n",
    "            \n",
    "        if query is None:\n",
    "            df = pd.concat([df,\n",
    "                            transform_cols(\n",
    "                                chunk_df[fields])], ignore_index=True)\n",
    "        else:\n",
    "            df = pd.concat([df,\n",
    "                            transform_cols(\n",
    "                                chunk_df).query(query)[fields]], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def features_handler(chunk_names, calc_feat, query=None, chunk_size=5000):\n",
    "    res_df = pd.DataFrame()\n",
    "    for chunk_name in chunk_names:\n",
    "        \n",
    "        feat_chunk = calc_feat(\n",
    "            load_data(\n",
    "                chunk_name,\n",
    "                query=query,\n",
    "                dict_col_types=None)\n",
    "        )\n",
    "\n",
    "        res_df = pd.concat([res_df, feat_chunk], ignore_index=True)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def cust_mark_to_class(custom_mark):\n",
    "    \"\"\"\n",
    "    Преобразует входящее значение CUSTOM_MARK в класс\n",
    "    return:\n",
    "        1 - фрод\n",
    "        0 - легитимная\n",
    "        -1 - неизвестно\n",
    "    \"\"\"\n",
    "    ret = -1\n",
    "    if custom_mark in ['F','S']:\n",
    "        ret = 1\n",
    "    elif custom_mark in ['A','G', np.NaN]:\n",
    "        ret = 0\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files is 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/train/chunk_0.fth',\n",
       " '../../data/raw_splits/train/chunk_1.fth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_N = 2\n",
    "N_THREADS = 16\n",
    "train_folder = '../../data/raw_splits/train/'\n",
    "train_files = sorted([x for x in os.listdir(train_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "train_files = [os.path.join(train_folder, x) for x in train_files]\n",
    "print(f'Length of train files is {len(train_files)}')\n",
    "train_files[:FIRST_N]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imp.reload(scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.read_feather('../data/raw_splits/train/{}'.format(chunk_names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include_channels = ['Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Перевод частному лицу',\n",
       " 'Оплата услуг',\n",
       " 'Перевод между своими счетами и картами']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = 20171029\n",
    "end_date = 20171128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file: ../data/raw_splits/train/../../data/raw_splits/train/chunk_9.fth , error: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-764605b62e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcalc_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_base_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     query=(\"event_description in {incl}  and short_date > {start} and short_date < {end}\"\n\u001b[0;32m----> 5\u001b[0;31m            .format(incl=include_channels, start=start_date, end=end_date)))\n\u001b[0m",
      "\u001b[0;32m/data/hse_nis/notebooks/data_preparation/scripts.py\u001b[0m in \u001b[0;36mfeatures_handler\u001b[0;34m(chunk_names, calc_feat, query, chunk_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mchunk_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 dict_col_types=None)\n\u001b[0m\u001b[1;32m    145\u001b[0m         )\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/hse_nis/notebooks/data_preparation/scripts.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(chunk_names, fields, query, sample, dict_col_types)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         chunk_df = pd.read_feather(\n\u001b[0;32m--> 120\u001b[0;31m             '../data/raw_splits/{smpl}/{ch_nm}'.format(smpl=sample, ch_nm=chunk_name))\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mfeather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(source, columns, nthreads)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfeather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.FeatherReader.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_reader\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.memory_map\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mio.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32merror.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file: ../data/raw_splits/train/../../data/raw_splits/train/chunk_9.fth , error: No such file or directory"
     ]
    }
   ],
   "source": [
    "feat_test = scr.features_handler(\n",
    "    chunk_names=[train_files[9]],\n",
    "    calc_feat = calc_base_features,\n",
    "    query=(\"event_description in {incl}  and short_date > {start} and short_date < {end}\"\n",
    "           .format(incl=include_channels, start=start_date, end=end_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(chunk_name):\n",
    "    #del feat_test\n",
    "    feat_test = features_handler(\n",
    "        chunk_names=[chunk_name],\n",
    "        calc_feat = calc_base_features,\n",
    "        # заменил > на >=\n",
    "        query=(\"event_description in {incl}  and short_date >= {start} and short_date =< {end}\"\n",
    "               .format(incl=include_channels, start=start_date, end=end_date)))\n",
    "    return feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file: ../data/raw_splits/train/../../data/raw_splits/train/chunk_0.fth , error: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/alex/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/alex/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-24c896bdf370>\", line 7, in get_data\n    .format(incl=include_channels, start=start_date, end=end_date)))\n  File \"/data/hse_nis/notebooks/data_preparation/scripts.py\", line 144, in features_handler\n    dict_col_types=None)\n  File \"/data/hse_nis/notebooks/data_preparation/scripts.py\", line 120, in load_data\n    '../data/raw_splits/{smpl}/{ch_nm}'.format(smpl=sample, ch_nm=chunk_name))\n  File \"/home/alex/anaconda3/lib/python3.6/site-packages/pandas/io/feather_format.py\", line 102, in read_feather\n    return feather.read_dataframe(path)\n  File \"/home/alex/anaconda3/lib/python3.6/site-packages/pyarrow/feather.py\", line 131, in read_feather\n    reader = FeatherReader(source)\n  File \"/home/alex/anaconda3/lib/python3.6/site-packages/pyarrow/feather.py\", line 43, in __init__\n    self.open(source)\n  File \"feather.pxi\", line 80, in pyarrow.lib.FeatherReader.open\n  File \"io.pxi\", line 798, in pyarrow.lib.get_reader\n  File \"io.pxi\", line 473, in pyarrow.lib.memory_map\n  File \"io.pxi\", line 452, in pyarrow.lib.MemoryMappedFile._open\n  File \"error.pxi\", line 79, in pyarrow.lib.check_status\npyarrow.lib.ArrowIOError: Failed to open local file: ../data/raw_splits/train/../../data/raw_splits/train/chunk_0.fth , error: No such file or directory\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dd015d732664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# жрет вплоть более 70 гигов оперативки, осторожнее\\nwith multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\\n    results = pool.map(get_data, train_files)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file: ../data/raw_splits/train/../../data/raw_splits/train/chunk_0.fth , error: No such file or directory"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# жрет вплоть более 70 гигов оперативки, осторожнее\n",
    "with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "    results = pool.map(get_data, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "for i, df in enumerate(results):\n",
    "    total_df = pd.concat([total_df, df])\n",
    "    results[i] = 'bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df['short_date'] = total_df.event_time.apply(lambda x: x.date())\n",
    "total_df.rename(columns={\"custom_mark\": \"label\"}, inplace=True)\n",
    "total_df['label'] = total_df.label.apply(lambda x: scr.cust_mark_to_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = total_df.query(\"label != -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_mean = np.mean(total_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_uniques = np.apply_along_axis(lambda x: len(np.unique(x)), axis=0, arr=total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total_df.to_csv(\"../data/coms_sep/train.csv\")\n",
    "total_df = pd.read_csv(\"../data/coms_sep/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_counter(data, field_name, target_name, alpha, global_mean=None):\n",
    "    if global_mean is None:\n",
    "        global_mean = data[target_name].mean()\n",
    "    counters = data.groupby(field_name)[target_name].mean()\n",
    "    n_counters = data.groupby(field_name)[target_name].count()\n",
    "    out = ((data[field_name].map(counters) + global_mean * alpha)/ \\\n",
    "           (data[field_name].map(n_counters) + alpha))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77143, 44679,     2, 75294, 13327, 18268,     3,     3,     1,\n",
       "           3,     2, 34704, 25670,   605,     2,   704,     8,     8,\n",
       "           8,     8,     8,   689,     8,     1,  5304,     2,   704,\n",
       "       13327,    14, 19904,    30])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'user_id', 'label', 'event_time', 'amount', 'client_age',\n",
       "       'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type', 'recip_age',\n",
       "       'age_diff', 'cumulative_sum_total', 'data_i_120', 'relative',\n",
       "       'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130', 'cdf_s_129',\n",
       "       'cdf_s_134', 'data_i_154', 'cdf_s_133', 'know_recip_card_age',\n",
       "       'recip_card_age', 'one_region', 'krp_pow2', 'log_amount', 'ip_isp',\n",
       "       'amnt2chnls', 'short_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in total_df.columns:\n",
    "    col_name = total_df.columns[i]\n",
    "    if col_name not in ['event_id', \"user_id\", \"event_time\", \"label\", \"short_date\"]:\n",
    "        total_df[col] = map_counter(total_df, col, 'label',\n",
    "                                    alpha=1000,\n",
    "                                    global_mean=global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_df.to_csv(\"../data/coms_sep/train_cntrs.csv\")\n",
    "#total_df = pd.read_csv(\"../data/coms_sep/train_cntrs.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63694\n",
       "1    13449\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пересборка датасета только для теста из-за ошибки в query для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '../../data/combined_dataset/'\n",
    "!mkdir -p $save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_normal_filename = '../../data/prepaired_dataset/train_v3.fth'\n",
    "test_normal_filename = '../../data/prepaired_dataset/test_v3.fth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_folder = '../../data/coms_sep/quantiles_data'\n",
    "quantiles_train_files = [os.path.join(quantiles_folder, x) for x in os.listdir(quantiles_folder) \n",
    "                         if (x.count('qnts_train')) and (not x.count('amount.csv'))]\n",
    "quantiles_test_files = [os.path.join(quantiles_folder, x) for x in os.listdir(quantiles_folder)\n",
    "                        if (x.count('qnts_test')) and (not x.count('amount.csv'))]\n",
    "assert len(quantiles_train_files) == len(quantiles_test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем обычный датасет с подсчитанными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_normal = pd.read_feather(train_normal_filename)\n",
    "test_normal = pd.read_feather(test_normal_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_normal['event_time'] = train_normal['event_time'].astype(str)\n",
    "test_normal['event_time'] = test_normal['event_time'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "#train_woe = pd.read_csv('../../data/coms_sep/train_woe.csv', index_col = 0, low_memory = False)\n",
    "test_woe = pd.read_csv('../../data/coms_sep/test_woe.csv', index_col = 0, low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обьединяем все датасеты с квантилями в один датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_quantiles(files):\n",
    "    quantiles_list = [pd.read_csv(x, low_memory = False, index_col = 0) for x in files]\n",
    "    uniq_ids_dates = lambda q_list: pd.concat([x[['user_id', 'short_date']] for x in q_list]).drop_duplicates().sort_values(['user_id', 'short_date']).reset_index().drop('index', axis = 1)\n",
    "    ids_dates = uniq_ids_dates(quantiles_list)\n",
    "    ids_dates_merged = ids_dates.copy()\n",
    "    for quant_df in tqdm_notebook(quantiles_list):\n",
    "        cols_for_na_fill = [x for x in quant_df.columns if not (x in ['user_id', 'short_date'])]\n",
    "        ids_dates_merged = ids_dates_merged.merge(quant_df, how = 'left', on = ['user_id', 'short_date'])\n",
    "        ids_dates_merged.loc[:, cols_for_na_fill] = ids_dates_merged.loc[:, cols_for_na_fill].fillna(-1000)\n",
    "    return ids_dates_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f9d02af5a643cb98380504bf82c14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6.96 s, sys: 3.17 s, total: 10.1 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train_quantiles = unite_quantiles(quantiles_train_files)\n",
    "test_quantiles = unite_quantiles(quantiles_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 180 ms, sys: 209 ms, total: 389 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train_quantiles.drop_duplicates(['user_id', 'short_date'], inplace = True)\n",
    "test_quantiles.drop_duplicates(['user_id', 'short_date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "соединяем normal с woe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_woe = train_woe.drop(['label', 'event_description', 'short_date'], axis = 1)\n",
    "train_woe.rename(columns = {x: f'woe_{x}' for x in  train_woe.columns if not x in ['event_time', 'user_id']},\n",
    "                 inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_woe = test_woe.drop(['event_description'], axis = 1)\n",
    "test_woe.rename(columns = {x: f'woe_{x}' for x in  test_woe.columns if not x in ['event_time', 'user_id']},\n",
    "                 inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_woe.drop_duplicates(['user_id', 'event_time'], inplace = True)\n",
    "test_woe.drop_duplicates(['user_id', 'event_time'], inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "tr_with_woe = train_normal.merge(train_woe, how = 'left', on = ['user_id', 'event_time'])\n",
    "tr_woe_cols = [x for x in tr_with_woe.columns if x.startswith('woe_')]\n",
    "tr_with_woe.loc[:, tr_woe_cols] = tr_with_woe.loc[:, tr_woe_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 s, sys: 3.02 s, total: 7.86 s\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "te_with_woe = test_normal.merge(test_woe, how = 'left', on = ['user_id', 'event_time'])\n",
    "te_woe_cols = [x for x in te_with_woe.columns if x.startswith('woe_')]\n",
    "te_with_woe.loc[:, te_woe_cols] = te_with_woe.loc[:, te_woe_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert tr_with_woe.shape[0] == train_normal.shape[0]\n",
    "assert te_with_woe.shape[0] == test_normal.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добавляем квантили"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "tr_combined = tr_with_woe.merge(train_quantiles, how = 'left', on = ['user_id', 'short_date'])\n",
    "tr_combined_quant_cols = [x for x in tr_combined.columns if x.count('_days_quantile_')]\n",
    "tr_combined.loc[:, tr_combined_quant_cols] = tr_combined.loc[:, tr_combined_quant_cols].fillna(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.04 s, sys: 4.34 s, total: 7.38 s\n",
      "Wall time: 7.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "te_combined = te_with_woe.merge(test_quantiles, how = 'left', on = ['user_id', 'short_date'])\n",
    "te_combined_quant_cols = [x for x in te_combined.columns if x.count('_days_quantile_')]\n",
    "te_combined.loc[:, te_combined_quant_cols] = te_combined.loc[:, te_combined_quant_cols].fillna(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert tr_combined.shape[0] == train_normal.shape[0]\n",
    "assert te_combined.shape[0] == test_normal.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сохраняем все"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 821 ms, sys: 1.07 s, total: 1.89 s\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tr_combined.to_feather(save_folder + 'train_v1.fth')\n",
    "te_combined.to_feather(save_folder + 'test_v1.fth')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(tr_combined.columns) - set(te_combined.columns), set(te_combined.columns) - set(tr_combined.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

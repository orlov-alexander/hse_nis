{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imp\n",
    "import scripts as scr\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytictoc import TicToc\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import datetime\n",
    "\n",
    "\n",
    "def transform_cols (df, dict_col_types = None):\n",
    "    # Расширяйте для необходимых столбцов и их явной типизации\n",
    "    if dict_col_types is None:\n",
    "        dict_col_types = {\n",
    "        'amount_original':(float, 0.0),\n",
    "        'channel_indicator_desc':(str, u'null'),\n",
    "        'event_description':(str, u'null'),\n",
    "        'short_date':(int, 0),\n",
    "        'cdf_s_20':(str, u'null'),\n",
    "        'cdf_s_126':(str, u'null'),\n",
    "        'cdf_s_127':(int, 30),\n",
    "        'cdf_s_129':(int, 30),\n",
    "        'cdf_s_138':(str, u'null'),\n",
    "        'cdf_s_130':(int, 30),\n",
    "        'cdf_s_133':(int, 30),\n",
    "        'cdf_s_134':(int, 30),\n",
    "        'cdf_s_135':(int, 30),\n",
    "        'cdf_s_140':(float, 0.0),\n",
    "        'cdf_s_218':(str, u'null'),\n",
    "        'cdf_s_294':(int, 0),\n",
    "        'cdf_s_299':(str, u'null'),\n",
    "        'data_s_65':(int, 0),\n",
    "        'data_i_120':(int, 0),\n",
    "        'data_i_154':(float, -150)\n",
    "        }\n",
    "                \n",
    "    if df.shape[0] == 0:\n",
    "        return df\n",
    "    \n",
    "    df.replace(u'null', np.nan, inplace=True)\n",
    "\n",
    "    for i in dict_col_types:\n",
    "        if i in df.columns:\n",
    "            change_type, fill_value = dict_col_types[i]\n",
    "            df[i] = df[i].fillna(fill_value).astype(change_type)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def calc_base_features(data):\n",
    "#     feat_matrix = pd.DataFrame()\n",
    "#     #data = data[data.event_description.isin([u'Перевод частному лицу',u'Оплата услуг',u'Перевод между своими счетами и картами'])]\n",
    "    \n",
    "#     if data.shape[0] == 0:\n",
    "#         return feat_matrix\n",
    "    \n",
    "#     # заполняем ряд пропусков\n",
    "\n",
    "#     # кумулятивная сумма опреаций за сутки, если не заполнена, то значит это первая операций, т.е. = 0\n",
    "#     data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float)/1000\n",
    "#     data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    \n",
    "#     feat_matrix['event_id'] = data.event_id\n",
    "#     feat_matrix['user_id'] = data.user_id\n",
    "#     feat_matrix['custom_mark'] = data.custom_mark    \n",
    "#     feat_matrix['event_time'] = data.event_time\n",
    "#     feat_matrix['amount'] = data.amount_original\n",
    "\n",
    "#     feat_matrix['data_i_120'] = data.data_i_120\n",
    "#     cdf_keep_cols = ['cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135']\n",
    "#     feat_matrix.loc[:, cdf_keep_cols] = data[cdf_keep_cols]\n",
    "#     feat_matrix['data_i_120'] = data.data_i_120\n",
    "\n",
    "#     # кумулятивная сумма операций за сутки в каналах web и МП\n",
    "#     feat_matrix['cumulative_sum_total'] = data.cdf_s_140\n",
    "\n",
    "    \n",
    "#     feat_matrix['client_age'] = [x.days/360 for x in (data.event_time - data.cdf_s_19)]\n",
    "  \n",
    "        \n",
    "#     feat_matrix['cat_new_ip'] = [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_126]\n",
    "#     feat_matrix['cat_new_prov'] =  [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_138]\n",
    "#     feat_matrix['channel_op'] =  [0 if x == u'MOBILE' else 1 if x == u'WEB' else 2 for x in data.channel_indicator_desc]\n",
    "#     feat_matrix['op_type'] = [0 if x == u'Перевод частному лицу' else 1 if x==u'Оплата услуг' else 2 if x ==u'Перевод между своими счетами и картами' else 3 for x in data.event_description]\n",
    "\n",
    "\n",
    "#     # бинарный флаг определяющий наличие возраста получателя\n",
    "#     # (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "#     feat_matrix['recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "#     # разница возорастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "#     feat_matrix['age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "    \n",
    "#     feat_matrix['relative'] = [1 if x == u'ДА' else 0 for x in data.cdf_s_218] # перевод родственнику\n",
    "    \n",
    "#     feat_matrix['know_recip_power'] = [ x if x is not None else 0 for x in data.data_s_65] # сила связи отправителя и получателя\n",
    "    \n",
    "\n",
    "#     feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "#     feat_matrix['know_recip_card_age'] = [1 if x is not None else 0 for x in data.cdf_s_124]\n",
    "    \n",
    "    \n",
    "#     feat_matrix['recip_card_age'] = [x.days if type(x) is not pd.tslib.NaTType else 912321 for x in (data.event_time - data.cdf_s_124)]\n",
    "    \n",
    "#     # feat_matrix['cat_client_region'] = [x if x.isdigit() else 912321 for x in data.cdf_s_20]\n",
    "#     feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "    \n",
    "\n",
    "#     #ADD NEW FEATURES\n",
    "#     feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "#     feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "#     feat_matrix['ip_isp'] = np.array([x if x.isdigit() else 912321 for x in data.cdf_s_20], dtype=float)\n",
    "#     feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0).astype(float) / \\\n",
    "#         (data[\"cdf_s_136\"].fillna(0).astype(float) + data[\"amount_original\"].fillna(0).astype(float) + \\\n",
    "#             data[\"amount_original\"].fillna(0) + 1))\n",
    "    \n",
    "#     # поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "#     order_cols = ['event_id', 'user_id', 'custom_mark', 'event_time', 'amount',\n",
    "#                   'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
    "#                   'recip_age', 'age_diff', 'cumulative_sum_total', 'data_i_120',\n",
    "#                   'relative', 'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130',\n",
    "#                   'cdf_s_129', 'cdf_s_134', 'data_i_154', 'cdf_s_133',\n",
    "#                   'know_recip_card_age', 'recip_card_age', 'one_region', 'krp_pow2',\n",
    "#                   'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "#     feat_mat = feat_mat[order_cols].copy()\n",
    "#     return feat_matrix\n",
    "\n",
    "\n",
    "def load_data(chunk_fnames, fields=None, query=None, sample='train', dict_col_types=None):\n",
    "    df = pd.DataFrame({})\n",
    "    if isinstance(chunk_fnames, str):\n",
    "        chunk_fnames = [chunk_fnames]\n",
    "        \n",
    "    for filename in chunk_fnames:\n",
    "        chunk_df = pd.read_feather(filename)\n",
    "            \n",
    "        if fields is None:\n",
    "            fields = chunk_df.columns.tolist()\n",
    "        \n",
    "        transormed = transform_cols(chunk_df)\n",
    "        \n",
    "        if query:\n",
    "            transormed = transormed.query(query)\n",
    " \n",
    "        df = pd.concat([df, transormed[fields]], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def features_handler(chunk_names, calc_feat, query=None, chunk_size=5000):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for chunk_name in chunk_names:\n",
    "        loaded_data = load_data(chunk_name, query=query, dict_col_types=None)\n",
    "        feat_chunk = calc_feat(loaded_data)\n",
    "        res_df = pd.concat([res_df, feat_chunk], ignore_index=True)\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def cust_mark_to_class(custom_mark):\n",
    "    \"\"\"\n",
    "    Преобразует входящее значение CUSTOM_MARK в класс\n",
    "    return:\n",
    "        1 - фрод\n",
    "        0 - легитимная\n",
    "        -1 - неизвестно\n",
    "    \"\"\"\n",
    "    ret = -1\n",
    "    if custom_mark in ['F','S']:\n",
    "        ret = 1\n",
    "    elif custom_mark in ['A','G', np.NaN]:\n",
    "        ret = 0\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files is 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/train/chunk_0.fth',\n",
       " '../../data/raw_splits/train/chunk_1.fth',\n",
       " '../../data/raw_splits/train/chunk_2.fth',\n",
       " '../../data/raw_splits/train/chunk_3.fth',\n",
       " '../../data/raw_splits/train/chunk_4.fth']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_N = 100\n",
    "N_THREADS = 16\n",
    "train_folder = '../../data/raw_splits/train/'\n",
    "train_files = sorted([x for x in os.listdir(train_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "train_files = [os.path.join(train_folder, x) for x in train_files]\n",
    "print(f'Length of train files is {len(train_files)}')\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imp.reload(scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.03 s, sys: 2.15 s, total: 6.18 s\n",
      "Wall time: 6.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_raw = pd.read_feather(train_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = transform_cols(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подробнее что есть что\n",
    "\n",
    "'event_id'- уникальный id транзакции\n",
    "\n",
    "'short_date' - дата (для удобства поиска/агрегации)\n",
    "\n",
    "'user_id' - уникальный идентификатор клиента\n",
    "\n",
    "'event_time' - дата и время собятия\n",
    "\n",
    "'custom_mark'- результат разбора события\n",
    "\n",
    "'channel_indicator_desc' - канал проведения операции (web, мобильное приложение, SMS-банк и пр.)\n",
    "\n",
    "'event_description' - описание непосредственно события (например, вход в систему или перевод, оплата услуг)\n",
    "\n",
    "'amount_original' - сумма в рублях\n",
    "\n",
    "'user_agent_string_hash', 'browser_plugins_hash', 'screen_hash' - различные признаки устройства (с определенной степенью точности позволяет понять уникальность устройства в разрезе пользователя)\n",
    "\n",
    "ip_address', 'ip_country', 'ip_region', 'ip_city', 'ip_isp' - данные, связанные с IP (регион, город и интернет-провадйер по БД гео-IP)\n",
    "'hardwareid' - уникальный идентификатор устройства для канала мобильных приложений\n",
    "\n",
    "'user_acct_number_hashed'- счет отправителя (хэшированный)\n",
    "'ext_acct_number_hashed'- счет получателя (хэшированный)\n",
    "\n",
    "\n",
    "'data_s_65' - результат определения связи между отправителем и получателем (чем больше, тем сильнее связь) \n",
    "'data_i_118', 'data_i_119’, 'data_i_120', 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    " \n",
    "\n",
    "\n",
    " 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП\n",
    " 'cdf_s_218'- предполагаемое наличие родственной связи \n",
    " 'cdf_s_127', 'cdf_s_135', 'cdf_s_130', 'cdf_s_129', 'cdf_s_134', 'cdf_s_128', 'cdf_s_138', 'cdf_s_126' - дней с момента различных рисковых событий\n",
    "\n",
    "\n",
    "\n",
    " 'cdf_s_19'- ДР клиента\n",
    " 'cdf_s_20'- Территориальный банк клиента (региональный признак)\n",
    " 'cdf_s_299'- Тер банк получателя (региональный признак)\n",
    "\n",
    " 'cdf_s_294'- возраст получателя\n",
    "\n",
    " 'cdf_s_123'- региональный признак получателя (более локальный по сравнению с ТБ)<br>\n",
    " 'cdf_s_124'- дата выдачи карты получателя\n",
    "\n",
    " 'cdf_s_178_hashed' - реквизит получателя"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#data = data[data.event_description.isin([u'Перевод частному лицу',u'Оплата услуг',u'Перевод между своими счетами и картами'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "tt = TicToc()\n",
    "tt.tic()\n",
    "\n",
    "feat_matrix = pd.DataFrame()\n",
    "\n",
    "if data.shape[0] == 0:\n",
    "    raise 'shape is 0'\n",
    "\n",
    "# заполняем ряд пропусков\n",
    "data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float) / 1000\n",
    "data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "feat_matrix['amount'] = data['amount_original']\n",
    "same_columns = ['event_id', 'user_id', 'event_time', \n",
    "                'cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135', 'data_i_120']\n",
    "for column in same_columns:\n",
    "    feat_matrix.loc[:, column] = data[column]\n",
    "feat_matrix['is_fraud'] = [cust_mark_to_class(x) for x in data['custom_mark']]\n",
    "    \n",
    "# ----------\n",
    "# дополнительные фичи\n",
    "# по user_id\n",
    "user_id_what_suffix = pd.Series([re.sub('[0-9]', '', x) for x in data['user_id']])\n",
    "for suffix in ['MBK', 'VSP', 'CRM', 'IVR', 'other']:\n",
    "    if suffix == 'other':\n",
    "        result = ~user_id_what_suffix.isin(['MBK', 'VSP', 'CRM', 'IVR', ''])\n",
    "    else:\n",
    "        result = (user_id_what_suffix == suffix).astype(int)\n",
    "    feat_matrix[f'user_id_{suffix}'] = result\n",
    "feat_matrix['user_id_digit_only'] = feat_matrix['user_id'].apply(lambda x: x.isdigit())\n",
    "# по каналу ohe\n",
    "for suffix in ['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK', 'other']:\n",
    "    if suffix == 'other':\n",
    "        result = ~data.channel_indicator_desc.isin(['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK'])\n",
    "    else:\n",
    "        result = (data.channel_indicator_desc == suffix).astype(int)\n",
    "    feat_matrix[f'channel_indicator_desc_is_{suffix}'] = result\n",
    "# время операции\n",
    "feat_matrix['event_hour'] = [x.hour for x in feat_matrix['event_time']]\n",
    "feat_matrix['event_hour_night'] = [1 if ((hour >= 23) or (hour <= 7)) else 0 for hour in feat_matrix['event_hour']]\n",
    "feat_matrix['event_hour_workhour'] = [1 if ((hour >= 8) or (hour <= 17)) else 0 for hour in feat_matrix['event_hour']]\n",
    "feat_matrix['event_hour_evening'] = [1 if ((hour >= 18) or (hour <= 22)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    \n",
    "feat_matrix['event_day'] = [x.dayofweek for x in feat_matrix['event_time']]\n",
    "feat_matrix['event_day_is_weekend'] = [1 if day >= 6 else 0 for day in feat_matrix['event_day']]\n",
    "# ----------\n",
    "\n",
    "tt.toc('First')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кумулятивная сумма операций за сутки в каналах web и МП, умножил на 1e15 из-за того, что там сильно маленькие числа\n",
    "feat_matrix['cumulative_sum_total'] = data.cdf_s_140 * 1e15\n",
    "\n",
    "\n",
    "feat_matrix['client_age'] = [x.days / 365.25 for x in (data.event_time - data.cdf_s_19)]\n",
    "feat_matrix['client_age_isnull'] = feat_matrix['client_age'].isnull().astype(int)\n",
    "\n",
    "#заменил на -1\n",
    "feat_matrix['cat_new_ip'] = [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_126]\n",
    "feat_matrix['cat_new_prov'] =  [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_138]\n",
    "feat_matrix['channel_op'] =  [0 if x == 'MOBILE' else 1 if x == 'WEB' else -1 for x in data.channel_indicator_desc]\n",
    "feat_matrix['op_type'] = [0 if x == 'Перевод частному лицу' else\n",
    "                          1 if x == 'Оплата услуг' else\n",
    "                          2 if x == 'Перевод между своими счетами и картами' else\n",
    "                          3 for x in data.event_description]\n",
    "\n",
    "tt.toc('Second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# бинарный флаг определяющий наличие возраста получателя\n",
    "# (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "feat_matrix['transfer_recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "# разница возрастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "feat_matrix['transfer_age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "# перевод родственнику\n",
    "feat_matrix['transfer_for_relative'] = [1 if x == 'ДА' else 0 for x in data.cdf_s_218] \n",
    "# сила связи отправителя и получателя\n",
    "feat_matrix['transfer_know_recip_squared'] = [ x if x is not None else 0 for x in data.data_s_65]\n",
    "# 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    "feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "# 'cdf_s_124'- дата выдачи карты получателя\n",
    "feat_matrix['know_recip_card_age'] = ~data.cdf_s_124.isnull().astype(int)\n",
    "# в cdf_s_124 подмешана дата рождения, поэтому и max\n",
    "feat_matrix['recip_card_age'] = [max(x.days, 1000) if type(x) is not pd.tslib.NaTType else 1000 \n",
    "                                 for x in (data.event_time - data.cdf_s_124)]\n",
    "\n",
    "# feat_matrix['cat_client_region'] = [x if x.isdigit() else 912321 for x in data.cdf_s_20]\n",
    "feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "\n",
    "# там с провайдером какая-то фигня до этого была (использовалась левая переменная)\n",
    "feat_matrix['ip_isp'] = data['ip_isp'].fillna(-1000000).astype(int)\n",
    "tt.toc('Third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ADD NEW FEATURES\n",
    "feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "\n",
    "feat_matrix['client_region_len'] = data.cdf_s_20.apply(lambda x: len(str(x)))\n",
    "feat_matrix['client_region'] = np.array([x if x.isdigit() else 999999 for x in data.cdf_s_20], dtype=float)\n",
    "# там какая-то фигня была, переписал по смыслу\n",
    "# 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП \n",
    "feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0) / \\\n",
    "    (data[\"cdf_s_136\"].fillna(0) + \\\n",
    "     data[\"cdf_s_136\"].fillna(0) + \\\n",
    "     data[\"cdf_s_140\"].fillna(0) + 1))\n",
    "tt.toc('Fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "order_cols = ['event_id', 'user_id', 'custom_mark', 'event_time', 'amount',\n",
    "              'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
    "              'recip_age', 'age_diff', 'cumulative_sum_total', 'data_i_120',\n",
    "              'relative', 'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130',\n",
    "              'cdf_s_129', 'cdf_s_134', 'data_i_154', 'cdf_s_133',\n",
    "              'know_recip_card_age', 'recip_card_age', 'one_region', 'krp_pow2',\n",
    "              'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "feat_matrix = feat_matrix[order_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['ip_isp'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[a] == 912321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ip_isp'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include_channels = ['Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = 20171029\n",
    "end_date = 20171128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_test = features_handler(\n",
    "    chunk_names=[train_files[9]],\n",
    "    calc_feat = calc_base_features,\n",
    "    query=(\"event_description in {incl}  and short_date > {start} and short_date < {end}\"\n",
    "           .format(incl=include_channels, start=start_date, end=end_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(chunk_name):\n",
    "    #del feat_test\n",
    "    feat_test = features_handler(\n",
    "        chunk_names=[chunk_name],\n",
    "        calc_feat = calc_base_features,\n",
    "        # заменил > на >=\n",
    "        query=(\"event_description in {incl}  and short_date >= {start} and short_date =< {end}\"\n",
    "               .format(incl=include_channels, start=start_date, end=end_date)))\n",
    "    return feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# жрет вплоть более 70 гигов оперативки, осторожнее\n",
    "with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "    results = pool.map(get_data, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "for i, df in enumerate(results):\n",
    "    total_df = pd.concat([total_df, df])\n",
    "    results[i] = 'bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df['short_date'] = total_df.event_time.apply(lambda x: x.date())\n",
    "total_df.rename(columns={\"custom_mark\": \"label\"}, inplace=True)\n",
    "total_df['label'] = total_df.label.apply(lambda x: scr.cust_mark_to_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = total_df.query(\"label != -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_mean = np.mean(total_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_uniques = np.apply_along_axis(lambda x: len(np.unique(x)), axis=0, arr=total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total_df.to_csv(\"../data/coms_sep/train.csv\")\n",
    "total_df = pd.read_csv(\"../data/coms_sep/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_counter(data, field_name, target_name, alpha, global_mean=None):\n",
    "    if global_mean is None:\n",
    "        global_mean = data[target_name].mean()\n",
    "    counters = data.groupby(field_name)[target_name].mean()\n",
    "    n_counters = data.groupby(field_name)[target_name].count()\n",
    "    out = ((data[field_name].map(counters) + global_mean * alpha)/ \\\n",
    "           (data[field_name].map(n_counters) + alpha))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in total_df.columns:\n",
    "    col_name = total_df.columns[i]\n",
    "    if col_name not in ['event_id', \"user_id\", \"event_time\", \"label\", \"short_date\"]:\n",
    "        total_df[col] = map_counter(total_df, col, 'label',\n",
    "                                    alpha=1000,\n",
    "                                    global_mean=global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_df.to_csv(\"../data/coms_sep/train_cntrs.csv\")\n",
    "#total_df = pd.read_csv(\"../data/coms_sep/train_cntrs.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytictoc as ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Downloading joblib-0.11-py2.py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib\n",
      "Successfully installed joblib-0.11\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kamaldinov Ildar (kamildraf@gmail.com)\n",
    "# MIT License\n",
    "import numpy as np\n",
    "\n",
    "def gini(y, **kwargs):\n",
    "    prob = np.sum(y) / len(y)\n",
    "    return prob * (1 - prob)\n",
    "\n",
    "\n",
    "def entropy(y, smooth=0, **kwargs):\n",
    "    prob = np.sum(y) / len(y)\n",
    "    return (- prob * np.log(prob + smooth))\n",
    "\n",
    "\n",
    "class OneFeatureTree(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 criterion,\n",
    "                 min_samples_leaf=2,\n",
    "                 smooth_woe=0.001,\n",
    "                 min_samples_class=1,\n",
    "                 max_depth=None,\n",
    "                 smooth_entropy=0.001,\n",
    "                 dtype=np.float32):\n",
    "        self._criterion = criterion\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "        self._min_samples_class = min_samples_class\n",
    "        self._smooth_woe = smooth_woe\n",
    "        self._dtype = dtype\n",
    "        self._smooth_entropy = smooth_entropy\n",
    "\n",
    "        self._tree = {}\n",
    "\n",
    "    def _split_vector(self, x, y, value):\n",
    "        left_ind = x < value\n",
    "        left_x, right_x = x[left_ind], x[np.logical_not(left_ind)]\n",
    "        left_y, right_y = y[left_ind], y[np.logical_not(left_ind)]\n",
    "        return left_x, right_x, left_y, right_y\n",
    "\n",
    "    def _calc_woe(self, y, smooth_woe):\n",
    "        n_pos = np.sum(y)\n",
    "        n_neg = np.float32(len(y)) - n_pos\n",
    "        woe = np.log((n_pos + smooth_woe) / (n_neg + smooth_woe))\n",
    "        return woe\n",
    "\n",
    "    def _split(self, x, y):\n",
    "        if self._criterion == 'gini':\n",
    "            splitter = gini\n",
    "        elif self._criterion == 'entropy':\n",
    "            splitter = entropy\n",
    "        else:\n",
    "            assert callable(self._criterion)\n",
    "\n",
    "        n_obs = len(y)\n",
    "        y = y[np.argsort(x)]\n",
    "\n",
    "        x_info = np.unique(x, return_counts=True)\n",
    "\n",
    "        impurities = np.zeros(len(x_info[0]) - 1)\n",
    "        for ind, n_left in enumerate(np.cumsum(x_info[1])[:-1]):\n",
    "            impurities[ind] = (\n",
    "                (splitter(y[:n_left],\n",
    "                          smooth=self._smooth_entropy) * n_left +\n",
    "                 splitter(y[n_left:],\n",
    "                          smooth=self._smooth_entropy) * (n_obs - n_left)) \\\n",
    "                / n_obs)\n",
    "        thresh_ind = np.argmin(impurities)\n",
    "        threshold = np.mean(\n",
    "            x_info[0][[thresh_ind, thresh_ind + 1]])\n",
    "        return threshold\n",
    "\n",
    "    def _fit_node(self, x, y,\n",
    "                  depth, node):\n",
    "\n",
    "        min_samples = (len(y) > self._min_samples_leaf)\n",
    "        uniq_x = len(np.unique(x)) > 1\n",
    "        n_pos = np.sum(y)\n",
    "        n_neg = len(y) - n_pos\n",
    "        min_class = np.all(np.array([n_pos, n_neg]) >= self._min_samples_class)\n",
    "        max_depth = ((depth < self._max_depth)\n",
    "                     if self._max_depth is not None else True)\n",
    "\n",
    "        if (min_samples and min_class and max_depth and uniq_x):\n",
    "            # zero node type for non-terminal nodes\n",
    "            node['type'] = 0\n",
    "\n",
    "            threshold = self._split(x, y)\n",
    "            left_x, right_x, left_y, right_y = self._split_vector(\n",
    "                x, y, threshold)\n",
    "\n",
    "            # 0 -- left_child, 1 -- right child\n",
    "            node[0] = {}\n",
    "            node[1] = {}\n",
    "            node['thresh'] = threshold\n",
    "            self._fit_node(left_x, left_y,\n",
    "                           depth + 1,\n",
    "                           node[0])\n",
    "            self._fit_node(right_x, right_y,\n",
    "                           depth + 1,\n",
    "                           node[1])\n",
    "        else:\n",
    "            node['type'] = 1\n",
    "            node['woe'] = self._calc_woe(y, self._smooth_woe)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x, dtype=self._dtype)\n",
    "        y = np.array(y, dtype=self._dtype)\n",
    "\n",
    "        self._fit_node(x, y, depth=0, node=self._tree)\n",
    "        return self\n",
    "\n",
    "    def _transform_node(self, x, node):\n",
    "        if node['type'] == 0:\n",
    "            if x < node['thresh']:\n",
    "                return self._transform_node(x, node[0])\n",
    "            else:\n",
    "                return self._transform_node(x, node[1])\n",
    "        return node['woe']\n",
    "\n",
    "    def transform(self, x):\n",
    "        if len(self._tree) == 0:\n",
    "            return \"Not trained yet\"\n",
    "        transformed = np.zeros_like(x, dtype=self._dtype)\n",
    "        for ind in range(len(x)):\n",
    "            transformed[ind] = self._transform_node(x[ind], self._tree)\n",
    "        return transformed\n",
    "\n",
    "    def fit_transform(self, x, y):\n",
    "        self.fit(x, y)\n",
    "        return self.transform(x)\n",
    "\n",
    "# Author: Kamaldinov Ildar (kamildraf@gmail.com)\n",
    "# MIT License\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class WoeTree(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 criterion,\n",
    "                 max_depth=None,\n",
    "                 min_samples_leaf=2,\n",
    "                 min_samples_class=1,\n",
    "                 smooth_woe=0.001,\n",
    "                 n_jobs=1,\n",
    "                 dtype=np.float32):\n",
    "        self._criterion = criterion\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "        self._min_samples_class = min_samples_class\n",
    "        self._smooth_woe = smooth_woe\n",
    "        self._n_jobs = n_jobs\n",
    "        self._dtype = dtype\n",
    "\n",
    "        self._trees = []\n",
    "\n",
    "    def _to_arglist(self, arg, shape):\n",
    "        if isinstance(arg, list):\n",
    "            return arg\n",
    "        else:\n",
    "            return [arg] * shape\n",
    "\n",
    "    def _fit(self, feature):\n",
    "        self._trees[feature].fit(X[:, feature], y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        criterion = self._to_arglist(self._criterion, n_features)\n",
    "        max_depth = self._to_arglist(self._max_depth, n_features)\n",
    "        min_samples_leaf = self._to_arglist(self._min_samples_leaf, n_features)\n",
    "        min_samples_class = self._to_arglist(\n",
    "            self._min_samples_class, n_features)\n",
    "        smooth_woe = self._to_arglist(self._smooth_woe, n_features)\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            self._trees.append(\n",
    "                OneFeatureTree(\n",
    "                    criterion=criterion[feature],\n",
    "                    max_depth=max_depth[feature],\n",
    "                    min_samples_leaf=min_samples_leaf[feature],\n",
    "                    min_samples_class=min_samples_class[feature],\n",
    "                    smooth_woe=smooth_woe[feature]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self._trees = (Parallel(n_jobs=self._n_jobs)\n",
    "            (delayed(self._trees[feature].fit)(X[:, feature], y)\n",
    "                for feature in range(n_features)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed = (Parallel(n_jobs=self._n_jobs)\n",
    "            (delayed(self._trees[ind].transform)(X[:, ind])\n",
    "                for ind in range(X.shape[1])))\n",
    "        return np.array(transformed).T\n",
    "\n",
    "    def fit_transfrom(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-890dcd0573e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/coms_sep/train_no_cnts.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/coms_sep/test_no_cnts.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/coms_sep/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/coms_sep/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \"\"\"\n\u001b[1;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_train = pd.read_csv(\"../../data/coms_sep/train_no_cnts.csv\", index_col=0)\n",
    "raw_test = pd.read_csv(\"../../data/coms_sep/test_no_cnts.csv\", index_col=0)\n",
    "train = pd.read_csv(\"../../data/coms_sep/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"../../data/coms_sep/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_cat = ['cat_new_ip',\n",
    "             'cat_new_prov',\n",
    "             'op_type',\n",
    "             'relative',\n",
    "             'cdf_s_127',\n",
    "             'cdf_s_135',\n",
    "             'cdf_s_130',\n",
    "             'cdf_s_129',\n",
    "             'cdf_s_134',\n",
    "             'cdf_s_133',\n",
    "             'know_recip_card_age',\n",
    "             'one_region']\n",
    "\n",
    "feats_num = ['amount',\n",
    "              'client_age',\n",
    "              'age_diff',\n",
    "              'cumulative_sum_total',\n",
    "              'cumulative_sum_total',\n",
    "              'data_i_120',\n",
    "              'know_recip_power',\n",
    "              'data_i_120',\n",
    "              'recip_card_age',\n",
    "              'krp_pow2',\n",
    "              'log_amount']\n",
    "feats = feats_cat + feats_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_tree = WoeTree('entropy', max_depth=4, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WoeTree at 0x7fb5a2e0aa58>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woe_tree.fit(raw_train.loc[:, feats].values, raw_train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 30.724023 seconds.\n",
      "Elapsed time is 30.540150 seconds.\n"
     ]
    }
   ],
   "source": [
    "tt = ptt.TicToc()\n",
    "tt.tic()\n",
    "woe_train = woe_tree.transform(raw_train.loc[:, feats].values)\n",
    "tt.toc()\n",
    "tt.tic()\n",
    "woe_test = woe_tree.transform(raw_train.loc[:, feats].values)\n",
    "tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_cols = raw_train.columns[np.logical_not(np.in1d(raw_train.columns, feats))].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.concat([raw_train.reset_index()[aux_cols], \n",
    "                      pd.DataFrame(woe_train, columns=feats)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_cols.remove('label')\n",
    "aux_cols.remove('short_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.concat([raw_test.reset_index()[aux_cols], \n",
    "                      pd.DataFrame(woe_test, columns=feats)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(\"../../data/coms_sep/train_woe.csv\")\n",
    "new_test.to_csv(\"../../data/coms_sep/test_woe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytictoc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18e7c07348a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytictoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTicToc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytictoc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imp\n",
    "import scripts as scr\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytictoc import TicToc\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import datetime\n",
    "\n",
    "\n",
    "def transform_cols (df, dict_col_types = None):\n",
    "    # Расширяйте для необходимых столбцов и их явной типизации\n",
    "    if dict_col_types is None:\n",
    "        dict_col_types = {\n",
    "        'amount_original':(float, 0.0),\n",
    "        'channel_indicator_desc':(str, u'null'),\n",
    "        'event_description':(str, u'null'),\n",
    "        'short_date':(int, 0),\n",
    "        'cdf_s_20':(str, u'null'),\n",
    "        'cdf_s_126':(str, u'null'),\n",
    "        'cdf_s_127':(int, 30),\n",
    "        'cdf_s_129':(int, 30),\n",
    "        'cdf_s_138':(str, u'null'),\n",
    "        'cdf_s_130':(int, 30),\n",
    "        'cdf_s_133':(int, 30),\n",
    "        'cdf_s_134':(int, 30),\n",
    "        'cdf_s_135':(int, 30),\n",
    "        'cdf_s_140':(float, 0.0),\n",
    "        'cdf_s_218':(str, u'null'),\n",
    "        'cdf_s_294':(int, 0),\n",
    "        'cdf_s_299':(str, u'null'),\n",
    "        'data_s_65':(int, 0),\n",
    "        'data_i_120':(int, 0),\n",
    "        'data_i_154':(float, -150)\n",
    "        }\n",
    "                \n",
    "    if df.shape[0] == 0:\n",
    "        return df\n",
    "    \n",
    "    df.replace(u'null', np.nan, inplace=True)\n",
    "\n",
    "    for i in dict_col_types:\n",
    "        if i in df.columns:\n",
    "            change_type, fill_value = dict_col_types[i]\n",
    "            df[i] = df[i].fillna(fill_value).astype(change_type)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def calc_base_features(data):\n",
    "#     feat_matrix = pd.DataFrame()\n",
    "#     #data = data[data.event_description.isin([u'Перевод частному лицу',u'Оплата услуг',u'Перевод между своими счетами и картами'])]\n",
    "    \n",
    "#     if data.shape[0] == 0:\n",
    "#         return feat_matrix\n",
    "    \n",
    "#     # заполняем ряд пропусков\n",
    "\n",
    "#     # кумулятивная сумма опреаций за сутки, если не заполнена, то значит это первая операций, т.е. = 0\n",
    "#     data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float)/1000\n",
    "#     data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    \n",
    "#     feat_matrix['event_id'] = data.event_id\n",
    "#     feat_matrix['user_id'] = data.user_id\n",
    "#     feat_matrix['custom_mark'] = data.custom_mark    \n",
    "#     feat_matrix['event_time'] = data.event_time\n",
    "#     feat_matrix['amount'] = data.amount_original\n",
    "\n",
    "#     feat_matrix['data_i_120'] = data.data_i_120\n",
    "#     cdf_keep_cols = ['cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135']\n",
    "#     feat_matrix.loc[:, cdf_keep_cols] = data[cdf_keep_cols]\n",
    "#     feat_matrix['data_i_120'] = data.data_i_120\n",
    "\n",
    "#     # кумулятивная сумма операций за сутки в каналах web и МП\n",
    "#     feat_matrix['cumulative_sum_total'] = data.cdf_s_140\n",
    "\n",
    "    \n",
    "#     feat_matrix['client_age'] = [x.days/360 for x in (data.event_time - data.cdf_s_19)]\n",
    "  \n",
    "        \n",
    "#     feat_matrix['cat_new_ip'] = [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_126]\n",
    "#     feat_matrix['cat_new_prov'] =  [1 if x == u'ДА' else 0 if x == u'НЕТ' else 2 for x in data.cdf_s_138]\n",
    "#     feat_matrix['channel_op'] =  [0 if x == u'MOBILE' else 1 if x == u'WEB' else 2 for x in data.channel_indicator_desc]\n",
    "#     feat_matrix['op_type'] = [0 if x == u'Перевод частному лицу' else 1 if x==u'Оплата услуг' else 2 if x ==u'Перевод между своими счетами и картами' else 3 for x in data.event_description]\n",
    "\n",
    "\n",
    "#     # бинарный флаг определяющий наличие возраста получателя\n",
    "#     # (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "#     feat_matrix['recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "#     # разница возорастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "#     feat_matrix['age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "    \n",
    "#     feat_matrix['relative'] = [1 if x == u'ДА' else 0 for x in data.cdf_s_218] # перевод родственнику\n",
    "    \n",
    "#     feat_matrix['know_recip_power'] = [ x if x is not None else 0 for x in data.data_s_65] # сила связи отправителя и получателя\n",
    "    \n",
    "\n",
    "#     feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "#     feat_matrix['know_recip_card_age'] = [1 if x is not None else 0 for x in data.cdf_s_124]\n",
    "    \n",
    "    \n",
    "#     feat_matrix['recip_card_age'] = [x.days if type(x) is not pd.tslib.NaTType else 912321 for x in (data.event_time - data.cdf_s_124)]\n",
    "    \n",
    "#     # feat_matrix['cat_client_region'] = [x if x.isdigit() else 912321 for x in data.cdf_s_20]\n",
    "#     feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "    \n",
    "\n",
    "#     #ADD NEW FEATURES\n",
    "#     feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "#     feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "#     feat_matrix['ip_isp'] = np.array([x if x.isdigit() else 912321 for x in data.cdf_s_20], dtype=float)\n",
    "#     feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0).astype(float) / \\\n",
    "#         (data[\"cdf_s_136\"].fillna(0).astype(float) + data[\"amount_original\"].fillna(0).astype(float) + \\\n",
    "#             data[\"amount_original\"].fillna(0) + 1))\n",
    "    \n",
    "#     # поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "#     order_cols = ['event_id', 'user_id', 'custom_mark', 'event_time', 'amount',\n",
    "#                   'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type',\n",
    "#                   'recip_age', 'age_diff', 'cumulative_sum_total', 'data_i_120',\n",
    "#                   'relative', 'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130',\n",
    "#                   'cdf_s_129', 'cdf_s_134', 'data_i_154', 'cdf_s_133',\n",
    "#                   'know_recip_card_age', 'recip_card_age', 'one_region', 'krp_pow2',\n",
    "#                   'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "#     feat_mat = feat_mat[order_cols].copy()\n",
    "#     return feat_matrix\n",
    "\n",
    "\n",
    "def load_data(chunk_fnames, fields=None, query=None, sample='train', dict_col_types=None):\n",
    "    df = pd.DataFrame({})\n",
    "    if isinstance(chunk_fnames, str):\n",
    "        chunk_fnames = [chunk_fnames]\n",
    "        \n",
    "    for filename in chunk_fnames:\n",
    "        chunk_df = pd.read_feather(filename)\n",
    "            \n",
    "        if fields is None:\n",
    "            fields = chunk_df.columns.tolist()\n",
    "        \n",
    "        transormed = transform_cols(chunk_df)\n",
    "        \n",
    "        if query:\n",
    "            transormed = transormed.query(query)\n",
    " \n",
    "        df = pd.concat([df, transormed[fields]], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def features_handler(chunk_names, calc_feat, query=None, chunk_size=5000):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for chunk_name in chunk_names:\n",
    "        loaded_data = load_data(chunk_name, query=query, dict_col_types=None)\n",
    "        feat_chunk = calc_feat(loaded_data)\n",
    "        res_df = pd.concat([res_df, feat_chunk], ignore_index=True)\n",
    "\n",
    "    return res_df\n",
    "\n",
    "def cust_mark_to_class(custom_mark):\n",
    "    \"\"\"\n",
    "    Преобразует входящее значение CUSTOM_MARK в класс\n",
    "    return:\n",
    "        1 - фрод\n",
    "        0 - легитимная\n",
    "        -1 - неизвестно\n",
    "    \"\"\"\n",
    "    ret = -1\n",
    "    if custom_mark in ['F','S']:\n",
    "        ret = 1\n",
    "    elif custom_mark in ['A','G', np.NaN]:\n",
    "        ret = 0\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test files is 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/test/chunk_0.fth',\n",
       " '../../data/raw_splits/test/chunk_1.fth',\n",
       " '../../data/raw_splits/test/chunk_2.fth',\n",
       " '../../data/raw_splits/test/chunk_3.fth',\n",
       " '../../data/raw_splits/test/chunk_4.fth']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder = '../../data/raw_splits/test/'\n",
    "test_files = sorted([x for x in os.listdir(test_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "test_files = [os.path.join(test_folder, x) for x in test_files]\n",
    "print(f'Length of test files is {len(test_files)}')\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files is 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/train/chunk_0.fth',\n",
       " '../../data/raw_splits/train/chunk_1.fth',\n",
       " '../../data/raw_splits/train/chunk_2.fth',\n",
       " '../../data/raw_splits/train/chunk_3.fth',\n",
       " '../../data/raw_splits/train/chunk_4.fth']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIRST_N = 100\n",
    "N_THREADS = 5\n",
    "train_folder = '../../data/raw_splits/train/'\n",
    "train_files = sorted([x for x in os.listdir(train_folder) if not '.pkl' in x], key = lambda x: int(re.sub('[^0-9]', '', x)))\n",
    "train_files = [os.path.join(train_folder, x) for x in train_files]\n",
    "print(f'Length of train files is {len(train_files)}')\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imp.reload(scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 1.48 s, total: 4.2 s\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_raw = pd.read_feather(train_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 1.49 s, total: 34.4 s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = transform_cols(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подробнее что есть что\n",
    "\n",
    "'event_id'- уникальный id транзакции\n",
    "\n",
    "'short_date' - дата (для удобства поиска/агрегации)\n",
    "\n",
    "'user_id' - уникальный идентификатор клиента\n",
    "\n",
    "'event_time' - дата и время собятия\n",
    "\n",
    "'custom_mark'- результат разбора события\n",
    "\n",
    "'channel_indicator_desc' - канал проведения операции (web, мобильное приложение, SMS-банк и пр.)\n",
    "\n",
    "'event_description' - описание непосредственно события (например, вход в систему или перевод, оплата услуг)\n",
    "\n",
    "'amount_original' - сумма в рублях\n",
    "\n",
    "'user_agent_string_hash', 'browser_plugins_hash', 'screen_hash' - различные признаки устройства (с определенной степенью точности позволяет понять уникальность устройства в разрезе пользователя)\n",
    "\n",
    "ip_address', 'ip_country', 'ip_region', 'ip_city', 'ip_isp' - данные, связанные с IP (регион, город и интернет-провадйер по БД гео-IP)\n",
    "'hardwareid' - уникальный идентификатор устройства для канала мобильных приложений\n",
    "\n",
    "'user_acct_number_hashed'- счет отправителя (хэшированный)\n",
    "'ext_acct_number_hashed'- счет получателя (хэшированный)\n",
    "\n",
    "\n",
    "'data_s_65' - результат определения связи между отправителем и получателем (чем больше, тем сильнее связь) \n",
    "'data_i_118', 'data_i_119’, 'data_i_120', 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    " \n",
    "\n",
    "\n",
    " 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП\n",
    " 'cdf_s_218'- предполагаемое наличие родственной связи \n",
    " 'cdf_s_127', 'cdf_s_135', 'cdf_s_130', 'cdf_s_129', 'cdf_s_134', 'cdf_s_128', 'cdf_s_138', 'cdf_s_126' - дней с момента различных рисковых событий\n",
    "\n",
    "\n",
    "\n",
    " 'cdf_s_19'- ДР клиента\n",
    " 'cdf_s_20'- Территориальный банк клиента (региональный признак)\n",
    " 'cdf_s_299'- Тер банк получателя (региональный признак)\n",
    "\n",
    " 'cdf_s_294'- возраст получателя\n",
    "\n",
    " 'cdf_s_123'- региональный признак получателя (более локальный по сравнению с ТБ)<br>\n",
    " 'cdf_s_124'- дата выдачи карты получателя\n",
    "\n",
    " 'cdf_s_178_hashed' - реквизит получателя"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#data = data[data.event_description.isin([u'Перевод частному лицу',u'Оплата услуг',u'Перевод между своими счетами и картами'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 18.730778 seconds.\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "tt = TicToc()\n",
    "tt.tic()\n",
    "\n",
    "feat_matrix = pd.DataFrame()\n",
    "\n",
    "if data.shape[0] == 0:\n",
    "    raise 'shape is 0'\n",
    "\n",
    "# заполняем ряд пропусков\n",
    "data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float) / 1000\n",
    "data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "feat_matrix['amount'] = data['amount_original']\n",
    "same_columns = ['event_id', 'user_id', 'event_time', \n",
    "                'cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135', 'data_i_120']\n",
    "for column in same_columns:\n",
    "    feat_matrix.loc[:, column] = data[column]\n",
    "feat_matrix['is_fraud'] = [cust_mark_to_class(x) for x in data['custom_mark']]\n",
    "    \n",
    "\n",
    "# ----------\n",
    "# дополнительные фичи\n",
    "# по user_id\n",
    "user_id_what_suffix = pd.Series([re.sub('[0-9]', '', x) for x in data['user_id']])\n",
    "for suffix in ['MBK', 'VSP', 'CRM', 'IVR', 'other']:\n",
    "    if suffix == 'other':\n",
    "        result = ~user_id_what_suffix.isin(['MBK', 'VSP', 'CRM', 'IVR', ''])\n",
    "    else:\n",
    "        result = (user_id_what_suffix == suffix).astype(int)\n",
    "    feat_matrix[f'user_id_{suffix}'] = result\n",
    "feat_matrix['user_id_digit_only'] = feat_matrix['user_id'].apply(lambda x: x.isdigit())\n",
    "# по каналу ohe\n",
    "for suffix in ['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK', 'other']:\n",
    "    if suffix == 'other':\n",
    "        result = ~data.channel_indicator_desc.isin(['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK'])\n",
    "    else:\n",
    "        result = (data.channel_indicator_desc == suffix).astype(int)\n",
    "    feat_matrix[f'channel_indicator_desc_is_{suffix}'] = result\n",
    "# время операции\n",
    "feat_matrix['event_hour'] = [x.hour for x in feat_matrix['event_time']]\n",
    "feat_matrix['event_hour_night'] = [1 if ((hour >= 23) or (hour <= 7)) else 0 for hour in feat_matrix['event_hour']]\n",
    "feat_matrix['event_hour_workhour'] = [1 if ((hour >= 8) or (hour <= 17)) else 0 for hour in feat_matrix['event_hour']]\n",
    "feat_matrix['event_hour_evening'] = [1 if ((hour >= 18) or (hour <= 22)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    \n",
    "feat_matrix['event_day'] = [x.dayofweek for x in feat_matrix['event_time']]\n",
    "feat_matrix['event_day_is_weekend'] = [1 if day >= 6 else 0 for day in feat_matrix['event_day']]\n",
    "# ----------\n",
    "\n",
    "tt.toc('First')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second 36.774528 seconds.\n"
     ]
    }
   ],
   "source": [
    "# кумулятивная сумма операций за сутки в каналах web и МП, умножил на 1e15 из-за того, что там сильно маленькие числа\n",
    "feat_matrix['cumulative_sum_total'] = data.cdf_s_140 * 1e15\n",
    "\n",
    "\n",
    "feat_matrix['client_age'] = [x.days / 365.25 for x in (data.event_time - data.cdf_s_19)]\n",
    "feat_matrix['client_age_isnull'] = feat_matrix['client_age'].isnull().astype(int)\n",
    "\n",
    "#заменил на -1\n",
    "feat_matrix['cat_new_ip'] = [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_126]\n",
    "feat_matrix['cat_new_prov'] =  [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_138]\n",
    "feat_matrix['channel_op'] =  [0 if x == 'MOBILE' else 1 if x == 'WEB' else -1 for x in data.channel_indicator_desc]\n",
    "feat_matrix['op_type'] = [0 if x == 'Перевод частному лицу' else\n",
    "                          1 if x == 'Оплата услуг' else\n",
    "                          2 if x == 'Перевод между своими счетами и картами' else\n",
    "                          3 for x in data.event_description]\n",
    "\n",
    "tt.toc('Second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third 51.319204 seconds.\n"
     ]
    }
   ],
   "source": [
    "# бинарный флаг определяющий наличие возраста получателя\n",
    "# (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "feat_matrix['transfer_recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "# разница возрастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "feat_matrix['transfer_age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "# перевод родственнику\n",
    "feat_matrix['transfer_for_relative'] = [1 if x == 'ДА' else 0 for x in data.cdf_s_218] \n",
    "# сила связи отправителя и получателя\n",
    "feat_matrix['transfer_know_recip_squared'] = [ x if x is not None else 0 for x in data.data_s_65]\n",
    "# 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    "feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "# 'cdf_s_124'- дата выдачи карты получателя\n",
    "feat_matrix['know_recip_card_age'] = ~data.cdf_s_124.isnull().astype(int)\n",
    "# в cdf_s_124 подмешана дата рождения, поэтому и max\n",
    "feat_matrix['recip_card_age'] = [max(x.days, 1000) if type(x) is not pd.tslib.NaTType else 1000 \n",
    "                                 for x in (data.event_time - data.cdf_s_124)]\n",
    "\n",
    "# feat_matrix['cat_client_region'] = [x if x.isdigit() else 912321 for x in data.cdf_s_20]\n",
    "feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "\n",
    "# там с провайдером какая-то фигня до этого была (использовалась левая переменная)\n",
    "feat_matrix['ip_isp'] = data['ip_isp'].fillna(-1000000).astype(int)\n",
    "tt.toc('Third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставшиеся признаки из исходного набора\n",
    "feat_matrix['know_recip_power'] = [ x if x is not None else 0 for x in data.data_s_65] # сила связи отправителя и получателя\n",
    "feat_matrix['relative'] = [1 if x == u'ДА' else 0 for x in data.cdf_s_218] # перевод родственнику\n",
    "feat_matrix['age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294] # разница возорастов получателей и отправителей, если отсутствует/неприменимо, то padding 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourth 56.344418 seconds.\n"
     ]
    }
   ],
   "source": [
    "#ADD NEW FEATURES\n",
    "feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "\n",
    "feat_matrix['client_region_len'] = data.cdf_s_20.apply(lambda x: len(str(x)))\n",
    "feat_matrix['client_region'] = np.array([x if x.isdigit() else 999999 for x in data.cdf_s_20], dtype=float)\n",
    "# там какая-то фигня была, переписал по смыслу\n",
    "# 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП \n",
    "feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0) / \\\n",
    "    (data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "     data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "     data[\"cdf_s_140\"].fillna(0).astype(float) + 1))\n",
    "tt.toc('Fourth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "order_cols = ['event_id', 'user_id', 'is_fraud', 'event_time', 'amount',\n",
    "              'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type', \n",
    "              'age_diff', 'cumulative_sum_total', 'data_i_120',\n",
    "              'relative', 'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130',\n",
    "              'cdf_s_129', 'cdf_s_134', 'data_i_154', 'cdf_s_133',\n",
    "              'know_recip_card_age', 'recip_card_age', 'one_region', 'krp_pow2',\n",
    "              'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "feat_matrix = feat_matrix[order_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_channels = ['Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Перевод частному лицу',\n",
       " 'Оплата услуг',\n",
       " 'Перевод между своими счетами и картами']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_base_features(data, is_train=False):\n",
    "    feat_matrix = pd.DataFrame()\n",
    "    \n",
    "    if data.shape[0] == 0:\n",
    "        return feat_matrix\n",
    "    \n",
    "\n",
    "    feat_matrix = pd.DataFrame()\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        raise 'shape is 0'\n",
    "\n",
    "    # заполняем ряд пропусков\n",
    "    data.cdf_s_140 = data.cdf_s_140.fillna(0).astype(float) / 1000\n",
    "    data.data_i_120.fillna(1, inplace=True)\n",
    "\n",
    "    # column for check filtering\n",
    "    feat_matrix['event_description'] = data['event_description']\n",
    "    \n",
    "    feat_matrix['amount'] = data['amount_original']\n",
    "    same_columns = ['event_id', 'user_id', 'event_time', \n",
    "                    'cdf_s_127', 'cdf_s_129', 'cdf_s_130', 'cdf_s_133', 'cdf_s_134', 'cdf_s_135', 'data_i_120']\n",
    "    for column in same_columns:\n",
    "        feat_matrix.loc[:, column] = data[column]\n",
    "    \n",
    "    # create label only for train dataset\n",
    "    # feat_matrix['is_fraud'] = [cust_mark_to_class(x) for x in data['custom_mark']]\n",
    "        \n",
    "    # ----------\n",
    "    # дополнительные фичи\n",
    "    # по user_id\n",
    "    user_id_what_suffix = pd.Series([re.sub('[0-9]', '', x) for x in data['user_id']])\n",
    "    for suffix in ['MBK', 'VSP', 'CRM', 'IVR', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~user_id_what_suffix.isin(['MBK', 'VSP', 'CRM', 'IVR', ''])\n",
    "        else:\n",
    "            result = (user_id_what_suffix == suffix).astype(int)\n",
    "        feat_matrix[f'user_id_{suffix}'] = result\n",
    "    feat_matrix['user_id_digit_only'] = feat_matrix['user_id'].apply(lambda x: x.isdigit())\n",
    "    # по каналу ohe\n",
    "    for suffix in ['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK', 'other']:\n",
    "        if suffix == 'other':\n",
    "            result = ~data.channel_indicator_desc.isin(['MOBILEAPI', 'WEBAPI', 'ATMAPI', 'MBK'])\n",
    "        else:\n",
    "            result = (data.channel_indicator_desc == suffix).astype(int)\n",
    "        feat_matrix[f'channel_indicator_desc_is_{suffix}'] = result\n",
    "    # время операции\n",
    "    feat_matrix['event_hour'] = [x.hour for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_hour_night'] = [1 if ((hour >= 23) or (hour <= 7)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_workhour'] = [1 if ((hour >= 8) or (hour <= 17)) else 0 for hour in feat_matrix['event_hour']]\n",
    "    feat_matrix['event_hour_evening'] = [1 if ((hour >= 18) or (hour <= 22)) else 0 for hour in feat_matrix['event_hour']]\n",
    "        \n",
    "    feat_matrix['event_day'] = [x.dayofweek for x in feat_matrix['event_time']]\n",
    "    feat_matrix['event_day_is_weekend'] = [1 if day >= 6 else 0 for day in feat_matrix['event_day']]\n",
    "    # ----------\n",
    "    # кумулятивная сумма операций за сутки в каналах web и МП, умножил на 1e15 из-за того, что там сильно маленькие числа\n",
    "    feat_matrix['cumulative_sum_total'] = data.cdf_s_140 * 1e15\n",
    "\n",
    "\n",
    "    feat_matrix['client_age'] = [x.days / 365.25 for x in (data.event_time - data.cdf_s_19)]\n",
    "    feat_matrix['client_age_isnull'] = feat_matrix['client_age'].isnull().astype(int)\n",
    "\n",
    "    #заменил на -1\n",
    "    feat_matrix['cat_new_ip'] = [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_126]\n",
    "    feat_matrix['cat_new_prov'] =  [1 if x == 'ДА' else 0 if x == 'НЕТ' else -1 for x in data.cdf_s_138]\n",
    "    feat_matrix['channel_op'] =  [0 if x == 'MOBILE' else 1 if x == 'WEB' else -1 for x in data.channel_indicator_desc]\n",
    "    feat_matrix['op_type'] = [0 if x == 'Перевод частному лицу' else\n",
    "                              1 if x == 'Оплата услуг' else\n",
    "                              2 if x == 'Перевод между своими счетами и картами' else\n",
    "                              3 for x in data.event_description]\n",
    "\n",
    "    # бинарный флаг определяющий наличие возраста получателя\n",
    "    # (полезен для линейных моделей,  менее для деревьев с учетом следующего признака)\n",
    "    feat_matrix['transfer_recip_age'] = [1 if x == 0 else 0 for x in data.cdf_s_294]\n",
    "    # разница возрастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "    feat_matrix['transfer_age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294]\n",
    "    # перевод родственнику\n",
    "    feat_matrix['transfer_for_relative'] = [1 if x == 'ДА' else 0 for x in data.cdf_s_218] \n",
    "    # сила связи отправителя и получателя\n",
    "    feat_matrix['transfer_know_recip_squared'] = [ x if x is not None else 0 for x in data.data_s_65]\n",
    "    # 'data_i_154' - ряд признаков, которые описывают устройство, с которого проводятся операции\n",
    "    feat_matrix['data_i_154'] = [ x if x is not None else -150 for x in data.data_i_154]\n",
    "    # 'cdf_s_124'- дата выдачи карты получателя\n",
    "    feat_matrix['know_recip_card_age'] = ~data.cdf_s_124.isnull().astype(int)\n",
    "    # в cdf_s_124 подмешана дата рождения, поэтому и max\n",
    "    feat_matrix['recip_card_age'] = [max(x.days, 1000) if type(x) is not pd.tslib.NaTType else 1000 \n",
    "                                     for x in (data.event_time - data.cdf_s_124)]\n",
    "\n",
    "    feat_matrix['one_region'] = (data.cdf_s_20 == data.cdf_s_299).astype(int) # сравнение регионов\n",
    "\n",
    "    # там с провайдером какая-то фигня до этого была (использовалась левая переменная)\n",
    "    feat_matrix['ip_isp'] = data['ip_isp'].fillna(-1000000).astype(int)\n",
    "\n",
    "    # оставшиеся признаки из исходного набора\n",
    "    # сила связи отправителя и получателя\n",
    "    feat_matrix['know_recip_power'] = [ x if x is not None else 0 for x in data.data_s_65] \n",
    "    feat_matrix['relative'] = [1 if x == u'ДА' else 0 for x in data.cdf_s_218] # перевод родственнику\n",
    "    # разница возорастов получателей и отправителей, если отсутствует/неприменимо, то padding 500\n",
    "    feat_matrix['age_diff'] = feat_matrix.client_age - [int(x) if x != 0 else 1000 for x in data.cdf_s_294] \n",
    "\n",
    "    #ADD NEW FEATURES\n",
    "    # square of know_recip_power\n",
    "    feat_matrix['krp_pow2'] = (feat_matrix['know_recip_power']) ** 2\n",
    "    \n",
    "    # natural log of amount\n",
    "    feat_matrix['log_amount'] = np.log(feat_matrix['amount'] + 1)\n",
    "\n",
    "    # len and code of region name\n",
    "    feat_matrix['client_region_len'] = data.cdf_s_20.apply(lambda x: len(str(x)))\n",
    "    feat_matrix['client_region'] = np.array([x if x.isdigit() else -1 for x in data.cdf_s_20], dtype=float)\n",
    "    \n",
    "    # 'cdf_s_136','cdf_s_137','cdf_s_140'- кумулятивные суммы операций за сутки в web, МП, web + МП \n",
    "    feat_matrix['amnt2chnls'] = (data[\"amount_original\"].fillna(0) / \\\n",
    "        (data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "         data[\"cdf_s_136\"].fillna(0).astype(float) + \\\n",
    "         data[\"cdf_s_140\"].fillna(0).astype(float) + 1))\n",
    "\n",
    "    # поставил order_cols временно, чтобы сохранить такой же порядок как в оригинальном\n",
    "    order_cols = ['event_id', 'event_description', 'user_id', #'is_fraud',\n",
    "                  'event_time', 'amount',\n",
    "                  'client_age', 'cat_new_ip', 'cat_new_prov', 'channel_op', 'op_type', \n",
    "                  'age_diff', 'cumulative_sum_total', 'data_i_120',\n",
    "                  'relative', 'know_recip_power', 'cdf_s_127', 'cdf_s_135', 'cdf_s_130',\n",
    "                  'cdf_s_129', 'cdf_s_134', 'data_i_154', 'cdf_s_133',\n",
    "                  'know_recip_card_age', 'recip_card_age', 'one_region', 'krp_pow2',\n",
    "                  'log_amount', 'ip_isp', 'amnt2chnls']\n",
    "    return feat_matrix[order_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 20171029\n",
    "end_date = 20171128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"event_description in ({(str(include_channels))[1:-1]})\" + \\\n",
    "        f\" and short_date >= {str(start_date)}\" + \\\n",
    "        f\" and short_date <= {str(end_date)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"event_description in ('Перевод частному лицу', 'Оплата услуг', 'Перевод между своими счетами и картами') and short_date >= 20171029 and short_date <= 20171128\""
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(chunk_name):\n",
    "    feat_test = features_handler(\n",
    "        query = query,\n",
    "        chunk_names=[chunk_name],\n",
    "        calc_feat = calc_base_features)\n",
    "    return feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 s, sys: 2.31 s, total: 40.4 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_feats = get_data(train_files[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 2.95 s, total: 6.43 s\n",
      "Wall time: 9min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features matrix\n",
    "with multiprocessing.Pool(processes=min(N_THREADS, FIRST_N)) as pool:\n",
    "    results = pool.map(get_data, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "for i, df in enumerate(results):\n",
    "    total_df = pd.concat([total_df, df])\n",
    "    #results[i] = 'bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['short_date'] = total_df.event_time.apply(lambda x: x.date())\n",
    "total_df.rename(columns={\"is_fraud\": \"label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2017, 10, 29), datetime.date(2017, 11, 29))"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.short_date.min(), total_df.short_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1       3664\n",
       " 0    3802643\n",
       " 1      14012\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_description\n",
       "Оплата услуг                              1225172\n",
       "Перевод между своими счетами и картами     736091\n",
       "Перевод частному лицу                     1859056\n",
       "Name: event_description, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.groupby('event_description')['event_description'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "itog = total_df.query(\"label != -1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_uniques = np.apply_along_axis(lambda x: len(np.unique(x)), axis=0, arr=itog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = [\"cat_new_ip\", \"cat_new_prov\", \"op_type\", \"relative\",\n",
    "             \"cdf_s_127\", \"cdf_s_135\", \"cdf_s_130\", \"cdf_s_129\", \n",
    "             \"cdf_s_134\", \"cdf_s_133\", \"know_recip_card_age\",\n",
    "             \"one_region\"]\n",
    "num_feats = [\"amount\", \"client_age\", \"age_diff\", \"cumulative_sum_total\",\n",
    "             \"cumulative_sum_total\", \"data_i_120\", \"know_recip_power\",\n",
    "             \"data_i_120\", \"recip_card_age\", \"krp_pow2\", \"log_amount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/raw_splits/test/chunk_0.fth',\n",
       " '../../data/raw_splits/test/chunk_1.fth',\n",
       " '../../data/raw_splits/test/chunk_2.fth',\n",
       " '../../data/raw_splits/test/chunk_3.fth',\n",
       " '../../data/raw_splits/test/chunk_4.fth']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_date = 20171129\n",
    "test_end_date =  20171205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"event_description in ({(str(include_channels))[1:-1]})\" + \\\n",
    "        f\" and short_date >= {str(start_date)}\" + \\\n",
    "        f\" and short_date <= {str(end_date)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(chunk_name):\n",
    "    feat_test = features_handler(\n",
    "        query = query,\n",
    "        chunk_names=[chunk_name],\n",
    "        calc_feat = calc_base_features)\n",
    "    return feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 1.44 s, total: 3.21 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create features matrix\n",
    "with multiprocessing.Pool(processes=min(3, FIRST_N)) as pool:\n",
    "    res_test = pool.map(get_data, test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df_test = pd.DataFrame()\n",
    "for i, df in enumerate(res_test):\n",
    "    total_df_test = pd.concat([total_df_test, df])\n",
    "    #results[i] = 'bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "itog_test = total_df_test.copy()\n",
    "itog_test.drop('channel_op', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3816655, 30)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2035724, 29)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itog_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount                  float64\n",
       "client_age              float64\n",
       "age_diff                float64\n",
       "cumulative_sum_total    float64\n",
       "cumulative_sum_total    float64\n",
       "data_i_120                int64\n",
       "know_recip_power          int64\n",
       "data_i_120                int64\n",
       "recip_card_age            int64\n",
       "krp_pow2                  int64\n",
       "log_amount              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itog[num_feats].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_new_ip             int64\n",
       "cat_new_prov           int64\n",
       "op_type                int64\n",
       "relative               int64\n",
       "cdf_s_127              int64\n",
       "cdf_s_135              int64\n",
       "cdf_s_130              int64\n",
       "cdf_s_129              int64\n",
       "cdf_s_134              int64\n",
       "cdf_s_133              int64\n",
       "know_recip_card_age    int64\n",
       "one_region             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itog[cat_feats].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_op has only one unique values\n",
    "pd.DataFrame({\"feature\": itog.columns.tolist(), \"n_uniq\": (n_uniques.tolist())})\n",
    "itog.drop('channel_op', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class counter_cv:\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha,\n",
    "                 cv_internal=3,\n",
    "                 cv_external=3):\n",
    "\n",
    "        self._cv_internal = cv_internal\n",
    "        self._cv_external = cv_external\n",
    "        self._alpha = alpha\n",
    "\n",
    "    def _map_rule_cv(self, x, y, unique_x):\n",
    "        \"\"\"\n",
    "        create cv map rule\n",
    "        \"\"\"\n",
    "\n",
    "        map_rule_res = None\n",
    "\n",
    "        counter = pd.DataFrame({'x': x, 'y': y})\n",
    "        kf = KFold(n_splits=self._cv_internal)\n",
    "\n",
    "        for train_ind, test_ind in kf.split(x):\n",
    "            # mean for regularization\n",
    "            train_mean = np.mean(y[train_ind])\n",
    "\n",
    "            mean_by_cat = counter.iloc[train_ind, :].groupby('x')['y'].mean()\n",
    "            count_by_cat = counter.iloc[train_ind, :].groupby('x')['y'].count()\n",
    "\n",
    "            # smooth mean for categories\n",
    "            map_rule = ((mean_by_cat * count_by_cat +\n",
    "                         self._alpha * train_mean) /\n",
    "                        (count_by_cat + self._alpha))\n",
    "\n",
    "            # add missed categories to map rule\n",
    "            missed_cat = list(set(unique_x) - set(map_rule.index))\n",
    "            num_missed_cat = len(missed_cat)\n",
    "\n",
    "            if (num_missed_cat != 0):\n",
    "                map_rule.append(\n",
    "                    pd.Series(np.repeat(train_mean, num_missed_cat),\n",
    "                              index=missed_cat))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # create or update resulted map_rule\n",
    "            if (map_rule_res is None):\n",
    "                map_rule_res = map_rule / self._cv_internal\n",
    "            else:\n",
    "                map_rule_res += map_rule / self._cv_internal\n",
    "\n",
    "        return(map_rule_res)\n",
    "\n",
    "    def map_test(self, x_train, y_train, x_test):\n",
    "        \"\"\"\n",
    "        map categorial feature (x_test) based on mean values\n",
    "        of y in train sample\n",
    "\n",
    "        return numpy array, shape like x_test\n",
    "        \"\"\"\n",
    "\n",
    "        x_train = x_train.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        x_test = x_test.reset_index(drop=True)\n",
    "\n",
    "        # make pandas data frame for grouping and create map rule\n",
    "        counter = pd.DataFrame({'x': x_train, 'y': y_train})\n",
    "        map_rule = counter.groupby('x')['y'].mean()\n",
    "\n",
    "        return(x_test.map(map_rule))\n",
    "\n",
    "    def map_train(self, x, y):\n",
    "        \"\"\"\n",
    "        map categorial feature (x_train) based on double cross-validated\n",
    "        mean values\n",
    "\n",
    "        return numpy array, shape like y_train\n",
    "        \"\"\"\n",
    "\n",
    "        unique_x = np.unique(x)\n",
    "\n",
    "        x = x.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "\n",
    "        kf = KFold(n_splits=self._cv_external)\n",
    "\n",
    "        blank = np.zeros_like(y, dtype='float32')\n",
    "        for train_ind, test_ind in kf.split(x):\n",
    "            map_rule = self._map_rule_cv(x=x[train_ind],\n",
    "                                         y=y[train_ind],\n",
    "                                         unique_x=unique_x)\n",
    "\n",
    "            blank[test_ind] = x[test_ind].map(map_rule)\n",
    "\n",
    "        return(blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "itog.to_csv(\"../../data/coms_sep/train_no_cnts.csv\", index=False)\n",
    "itog_test.to_csv(\"../../data/coms_sep/test_no_cnts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 10.025378 seconds.\n",
      "Elapsed time is 10.085192 seconds.\n",
      "Elapsed time is 9.586066 seconds.\n",
      "Elapsed time is 10.024778 seconds.\n",
      "Elapsed time is 9.120979 seconds.\n",
      "Elapsed time is 9.546427 seconds.\n",
      "Elapsed time is 9.326977 seconds.\n",
      "Elapsed time is 9.585274 seconds.\n",
      "Elapsed time is 10.078037 seconds.\n",
      "Elapsed time is 10.970302 seconds.\n",
      "Elapsed time is 9.275317 seconds.\n",
      "Elapsed time is 9.824616 seconds.\n"
     ]
    }
   ],
   "source": [
    "for i in cat_feats:\n",
    "    tt = TicToc()\n",
    "    tt.tic()\n",
    "    counter = counter_cv(alpha=1000)\n",
    "    itog[i] = counter.map_train(itog[i], itog['label'])\n",
    "    itog_test[i] = counter.map_test(itog[i], itog['label'], itog_test[i])\n",
    "    tt.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "itog.to_csv(\"../../data/coms_sep/train.csv\", index=False)\n",
    "itog_test.to_csv(\"../../data/coms_sep/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itog.to_csv(\"../data/coms_sep/train.csv\")\n",
    "# total_df = pd.read_csv(\"../data/coms_sep/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = itog[['know_recip_card_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-d9659b91db81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'know_recip_card_age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: label'"
     ]
    }
   ],
   "source": [
    "x.groupby('know_recip_card_age')['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(itog['user_id'], pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter_cv(alpha=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:696: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "keka = counter.map_train(x=itog['op_type'], y=itog['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouterEncoder:\n",
    "    def __init__(alpha, feats, target):\n",
    "        self._alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            return \"X should be data frame\"\n",
    "        self._global_mean = np.mean(x)\n",
    "        self._counters = x.groupby()[target_name].mean()\n",
    "        self._n_counters = data.groupby()[target_name].count()\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            return \"X should be data frame\"\n",
    "            x = pd.Series(x)\n",
    "        out = ((x.map(self._counters) + self._global_mean * alpha) / \\\n",
    "               (x.map(self._n_counters) + alpha))\n",
    "        return out\n",
    "    \n",
    "    def fit_transform(x, y):\n",
    "        self.fit(x, y)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_counter(data, field_name, target_name, alpha, global_mean=None):\n",
    "    if global_mean is None:\n",
    "        global_mean = data[target_name].mean()\n",
    "    counters = data.groupby(field_name)[target_name].mean()\n",
    "    n_counters = data.groupby(field_name)[target_name].count()\n",
    "    out = ((data[field_name].map(counters) + global_mean * alpha)/ \\\n",
    "           (data[field_name].map(n_counters) + alpha))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in total_df.columns:\n",
    "    col_name = total_df.columns[i]\n",
    "    if col_name not in ['event_id', \"user_id\", \"event_time\", \"label\", \"short_date\"]:\n",
    "        total_df[col] = map_counter(total_df, col, 'label',\n",
    "                                    alpha=1000,\n",
    "                                    global_mean=global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_df.to_csv(\"../data/coms_sep/train_cntrs.csv\")\n",
    "#total_df = pd.read_csv(\"../data/coms_sep/train_cntrs.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

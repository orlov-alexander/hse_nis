{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import datetime\n",
    "import sklearn\n",
    "import sqlalchemy as sa\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "import operator\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 811 ms, sys: 2.19 s, total: 3.01 s\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_raw = pd.read_feather('../../data/prepaired_dataset/train_v2.fth')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "train_raw = pd.read_feather('../../data/prepaired_dataset/train_v2.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.loc[train_raw.label != -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_train, uid_val = train_test_split(sorted(train_raw['user_id'].unique()), test_size = 0.2, random_state = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(uid_train) & set(uid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['event_id', 'user_id', 'event_time', 'short_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20171029, 20171128)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['short_date'].min(), train_raw['short_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.27 s, sys: 6.24 s, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = train_raw.loc[train_raw['user_id'].isin(uid_train)].drop(drop_cols, axis = 1)\n",
    "dtrain = xgb.DMatrix(t.drop('label', axis = 1), label=t['label'], missing=np.NAN)\n",
    "t = train_raw.loc[train_raw['user_id'].isin(uid_val)].drop(drop_cols, axis = 1)\n",
    "dval = xgb.DMatrix(t.drop('label', axis = 1), label=t['label'], missing=np.NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del t, train_raw\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'max_depth': [3, 5], \n",
    "    'subsample': [0.4, 0.6], \n",
    "    'colsample_bytree': [0.5, 0.7], \n",
    "    'n_estimators': [150, 250],\n",
    "    'reg_alpha': [0.01, 0.03] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_params_list = []\n",
    "def cv_get(nxt, already = []):\n",
    "    global cv_params_list\n",
    "    if len(nxt) == 0:\n",
    "        return None\n",
    "    if len(nxt) == 1:\n",
    "        for k, v in nxt:\n",
    "            for vv in v:\n",
    "                cv_params_list.append(already + [(k, vv)])\n",
    "    else:\n",
    "        k, v = nxt.pop()\n",
    "        for vv in v:\n",
    "            already_cp = already.copy()\n",
    "            already_cp.append((k, vv))\n",
    "            cv_get(nxt.copy(), already_cp)\n",
    "            \n",
    "cv_get([(k, v) for k,v in sorted(params.items(), key = lambda x: x[0])])\n",
    "len(cv_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with grid search and early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa2087b98af4fd19f59a0cdb64b7293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003036\teval-error:0.003088\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-error:0.003045\teval-error:0.003068\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003021\teval-error:0.003094\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-error:0.003049\teval-error:0.003066\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[64]\ttrain-error:0.002855\teval-error:0.003021\n",
      "\n",
      "[0]\ttrain-error:0.003677\teval-error:0.00364\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.002755\teval-error:0.003037\n",
      "Stopping. Best iteration:\n",
      "[94]\ttrain-error:0.002772\teval-error:0.003028\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003036\teval-error:0.003088\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-error:0.003045\teval-error:0.003068\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003021\teval-error:0.003094\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-error:0.003049\teval-error:0.003066\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[64]\ttrain-error:0.002855\teval-error:0.003021\n",
      "\n",
      "[0]\ttrain-error:0.003677\teval-error:0.00364\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.002755\teval-error:0.003037\n",
      "Stopping. Best iteration:\n",
      "[94]\ttrain-error:0.002772\teval-error:0.003028\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003036\teval-error:0.003086\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-error:0.003054\teval-error:0.003071\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003034\teval-error:0.003078\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-error:0.003041\teval-error:0.003064\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-error:0.002836\teval-error:0.00301\n",
      "\n",
      "[0]\ttrain-error:0.003677\teval-error:0.00364\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-error:0.002923\teval-error:0.003084\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003036\teval-error:0.003086\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-error:0.003054\teval-error:0.003071\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003034\teval-error:0.003078\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-error:0.003041\teval-error:0.003064\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-error:0.002836\teval-error:0.00301\n",
      "\n",
      "[0]\ttrain-error:0.003677\teval-error:0.00364\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-error:0.002923\teval-error:0.003084\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003047\teval-error:0.003073\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-error:0.003076\teval-error:0.003038\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003042\teval-error:0.003104\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-error:0.002978\teval-error:0.003051\n",
      "\n",
      "[0]\ttrain-error:0.003625\teval-error:0.003613\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[65]\ttrain-error:0.002845\teval-error:0.003002\n",
      "\n",
      "[0]\ttrain-error:0.003675\teval-error:0.003627\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.002813\teval-error:0.003031\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003047\teval-error:0.003073\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-error:0.003076\teval-error:0.003038\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003042\teval-error:0.003104\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-error:0.002978\teval-error:0.003051\n",
      "\n",
      "[0]\ttrain-error:0.003625\teval-error:0.003613\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[65]\ttrain-error:0.002845\teval-error:0.003002\n",
      "\n",
      "[0]\ttrain-error:0.003675\teval-error:0.003627\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-error:0.002813\teval-error:0.003031\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.00305\teval-error:0.003069\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-error:0.003077\teval-error:0.003038\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003035\teval-error:0.00312\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-error:0.003058\teval-error:0.00311\n",
      "\n",
      "[0]\ttrain-error:0.003625\teval-error:0.003613\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-error:0.002861\teval-error:0.002994\n",
      "\n",
      "[0]\ttrain-error:0.003675\teval-error:0.003627\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[61]\ttrain-error:0.002846\teval-error:0.003046\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.00305\teval-error:0.003069\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-error:0.003077\teval-error:0.003038\n",
      "\n",
      "[0]\ttrain-error:0.003682\teval-error:0.003629\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "[100]\ttrain-error:0.003035\teval-error:0.00312\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-error:0.003058\teval-error:0.00311\n",
      "\n",
      "[0]\ttrain-error:0.003625\teval-error:0.003613\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-error:0.002861\teval-error:0.002994\n",
      "\n",
      "[0]\ttrain-error:0.003675\teval-error:0.003627\n",
      "Multiple eval metrics have been passed: 'eval-error' will be used for early stopping.\n",
      "\n",
      "Will train until eval-error hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[61]\ttrain-error:0.002846\teval-error:0.003046\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost with grid search and early stopping')\n",
    "# \n",
    "evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "num_round = 250\n",
    "models = []\n",
    "\n",
    "for chunk_params in tqdm_notebook([{k:v for k, v in x} for x in cv_params_list]):\n",
    "    i_params = chunk_params.copy()\n",
    "    i_params['n_jobs'] = 16\n",
    "    i_params['objective'] = 'binary:logistic'\n",
    "    bst = xgb.train(i_params, dtrain, num_round, evallist, verbose_eval=100, early_stopping_rounds = 20)\n",
    "    models.append((chunk_params, bst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9745258151694256\n",
      "1 0.9743437221890158\n",
      "2 0.9799422667593966\n",
      "3 0.9820631318228367\n",
      "4 0.9745258151694256\n",
      "5 0.9743437221890158\n",
      "6 0.9799422667593966\n",
      "7 0.9820631318228367\n",
      "8 0.9743927735440956\n",
      "9 0.9743864150544304\n",
      "10 0.9801170827755024\n",
      "11 0.978450818326852\n",
      "12 0.9743927735440956\n",
      "13 0.9743864150544304\n",
      "14 0.9801170827755024\n",
      "15 0.978450818326852\n",
      "16 0.9744473924397042\n",
      "17 0.9761290488899776\n",
      "18 0.9806959438795118\n",
      "19 0.9816410025576936\n",
      "20 0.9744473924397042\n",
      "21 0.9761290488899776\n",
      "22 0.9806959438795118\n",
      "23 0.9816410025576936\n",
      "24 0.9744783357322356\n",
      "25 0.9744713496248483\n",
      "26 0.9801490681877287\n",
      "27 0.980893441899248\n",
      "28 0.9744783357322356\n",
      "29 0.9744713496248483\n",
      "30 0.9801490681877287\n",
      "31 0.980893441899248\n"
     ]
    }
   ],
   "source": [
    "for n, (_, m) in enumerate(models):\n",
    "    print(n, roc_auc_score(dval.get_label(), m.predict(dval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_diff': 194,\n",
       " 'amnt2chnls': 162,\n",
       " 'amount': 163,\n",
       " 'cat_new_ip': 47,\n",
       " 'cat_new_prov': 37,\n",
       " 'cdf_s_127': 43,\n",
       " 'cdf_s_129': 43,\n",
       " 'cdf_s_130': 66,\n",
       " 'cdf_s_133': 31,\n",
       " 'cdf_s_134': 47,\n",
       " 'cdf_s_135': 26,\n",
       " 'channel_indicator_desc_is_MOBILEAPI': 8,\n",
       " 'channel_indicator_desc_is_WEBAPI': 9,\n",
       " 'client_age': 254,\n",
       " 'client_region': 85,\n",
       " 'cumulative_sum_total': 144,\n",
       " 'data_i_120': 67,\n",
       " 'data_i_154': 120,\n",
       " 'event_day': 56,\n",
       " 'event_day_is_weekend': 2,\n",
       " 'event_hour': 78,\n",
       " 'event_hour_night': 6,\n",
       " 'ip_isp': 117,\n",
       " 'know_recip_card_age': 8,\n",
       " 'know_recip_power': 75,\n",
       " 'krp_pow2': 31,\n",
       " 'log_amount': 53,\n",
       " 'one_region': 25,\n",
       " 'op_type': 36,\n",
       " 'recip_card_age': 18,\n",
       " 'relative': 12,\n",
       " 'transfer_age_diff': 57,\n",
       " 'transfer_for_relative': 5,\n",
       " 'transfer_know_recip_squared': 15,\n",
       " 'user_id_CRM': 1,\n",
       " 'user_id_MBK': 8,\n",
       " 'user_id_digit_only': 7}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

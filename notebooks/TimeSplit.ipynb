{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import datetime\n",
    "import sklearn\n",
    "import sqlalchemy as sa\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/alex/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "trans_feat = pd.read_csv('../data/data1per.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdf_s_123</th>\n",
       "      <th>cdf_s_124</th>\n",
       "      <th>cdf_s_127</th>\n",
       "      <th>cdf_s_135</th>\n",
       "      <th>cdf_s_130</th>\n",
       "      <th>cdf_s_129</th>\n",
       "      <th>cdf_s_134</th>\n",
       "      <th>cdf_s_128</th>\n",
       "      <th>cdf_s_138</th>\n",
       "      <th>cdf_s_126</th>\n",
       "      <th>...</th>\n",
       "      <th>user_acct_number_hashed</th>\n",
       "      <th>user_agent_string_hash</th>\n",
       "      <th>browser_plugins_hash</th>\n",
       "      <th>screen_hash</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>ip_country</th>\n",
       "      <th>ip_region</th>\n",
       "      <th>ip_city</th>\n",
       "      <th>ip_isp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "      <td>31.173.83.80</td>\n",
       "      <td>ru</td>\n",
       "      <td>48</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>7255560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "      <td>185.79.100.99</td>\n",
       "      <td>ru</td>\n",
       "      <td>48</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>6938077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "      <td>94.25.177.185</td>\n",
       "      <td>ru</td>\n",
       "      <td>48</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>7255560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "      <td>46.191.68.110</td>\n",
       "      <td>by</td>\n",
       "      <td>03</td>\n",
       "      <td>Grodno</td>\n",
       "      <td>190563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003</td>\n",
       "      <td>37.110.213.28</td>\n",
       "      <td>uz</td>\n",
       "      <td>13</td>\n",
       "      <td>Tashkent</td>\n",
       "      <td>5860113.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cdf_s_123 cdf_s_124  cdf_s_127  cdf_s_135  cdf_s_130  cdf_s_129  cdf_s_134  \\\n",
       "0       NaN       NaN         30          1         30         30          4   \n",
       "1       NaN       NaN         30          4         30         30          4   \n",
       "2       NaN       NaN         30          5         30         30         30   \n",
       "3       NaN       NaN         30          0         30         30         30   \n",
       "4       NaN       NaN         30         30         30         30          0   \n",
       "\n",
       "   cdf_s_128 cdf_s_138 cdf_s_126    ...      user_acct_number_hashed  \\\n",
       "0        NaN      null      null    ...                          NaN   \n",
       "1        NaN      null      null    ...                          NaN   \n",
       "2        NaN      null      null    ...                          NaN   \n",
       "3        NaN      null      null    ...                          NaN   \n",
       "4        NaN      null      null    ...                          NaN   \n",
       "\n",
       "   user_agent_string_hash  browser_plugins_hash  screen_hash user_id  \\\n",
       "0                     NaN                   NaN          NaN  100003   \n",
       "1                     NaN                   NaN          NaN  100003   \n",
       "2                     NaN                   NaN          NaN  100003   \n",
       "3                     NaN                   NaN          NaN  100003   \n",
       "4                     NaN                   NaN          NaN  100003   \n",
       "\n",
       "      ip_address ip_country ip_region   ip_city     ip_isp  \n",
       "0   31.173.83.80         ru        48    Moscow  7255560.0  \n",
       "1  185.79.100.99         ru        48    Moscow  6938077.0  \n",
       "2  94.25.177.185         ru        48    Moscow  7255560.0  \n",
       "3  46.191.68.110         by        03    Grodno   190563.0  \n",
       "4  37.110.213.28         uz        13  Tashkent  5860113.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df_from_sql(\"\"\"select channel_indicator_desc,\n",
    "                             cdf_s_138,\n",
    "                             cdf_s_126,\n",
    "                             cdf_s_218,\n",
    "                             event_description,\n",
    "                             cdf_s_136,\n",
    "                             cdf_s_137,\n",
    "                             cdf_s_140,\n",
    "                             amount_original,\n",
    "                             custom_mark from rsa_event_log LIMIT 100000\"\"\",\n",
    "                   engine=conn, parse_dates=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_feat['short_date'] = trans_feat.event_time.apply(lambda x: pd.to_datetime(x).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_feat['TS_indexer'] = trans_feat.short_date\n",
    "unique_TS_split = np.array(sorted(trans_feat.TS_indexer.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cust_mark_to_class(custom_mark):\n",
    "    \"\"\"\n",
    "    Преобразует входящее значение CUSTOM_MARK в класс\n",
    "    return:\n",
    "        1 - фрод\n",
    "        0 - легитимная\n",
    "        -1 - неизвестно\n",
    "    \"\"\"\n",
    "    ret = -1\n",
    "    if custom_mark in ['F','S']:\n",
    "        ret = 1\n",
    "    elif custom_mark in ['A','G', np.NaN]:\n",
    "        ret = 0\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_feat['lable'] = trans_feat.custom_mark.apply(lambda x: cust_mark_to_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_TS_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_megabatches(inputs, n_splits):\n",
    "    batchsize = len(unique_TS_split)//n_splits\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = [start_idx, start_idx + batchsize-1]\n",
    "        yield inputs[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_df_i_neg = pd.DataFrame()\n",
    "batch_df_pos = pd.DataFrame()\n",
    "for train_index in iterate_megabatches(inputs=unique_TS_split, n_splits=3):\n",
    "    batch_df_i_old_neg = batch_df_i_neg\n",
    "    batch_df_i = trans_feat[trans_feat.TS_indexer.isin(train_index)]\n",
    "    batch_df_i_pos = batch_df_i[batch_df_i.lable==1]\n",
    "    batch_df_i_neg = batch_df_i[batch_df_i.lable==0]\n",
    "    batch_df_pos = pd.concat([batch_df_pos, batch_df_i_pos])\n",
    "    batch_df_neg = pd.concat([batch_df_i_old_neg, batch_df_i_neg])\n",
    "    df_i = pd.concat([batch_df_pos, batch_df_neg])\n",
    "    #df_balanced_i = \n",
    "    #model = xgbclassifier()\n",
    "    #model.fit(df_balanced_i)\n",
    "    #pr_i = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(sub_y).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class forget_model(BaseEstimator):\n",
    "    def __init__(self, feature_types=['categorical'], max_depth=None,\n",
    "                 min_samples_split=None, min_samples_leaf=None):\n",
    "        if np.any(list(map(lambda x: x != \"real\" and x != \"categorical\",\n",
    "                           feature_types))):\n",
    "            raise ValueError(\"There is unknown feature type\")\n",
    "\n",
    "        self._tree = {}\n",
    "        self.feature_types = feature_types\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    def _fit_node(self, sub_X, sub_y, node):\n",
    "        if np.all(sub_y == sub_y[0]):\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = sub_y[0]\n",
    "            return\n",
    "        \n",
    "        if len(self.feature_types) == 1:\n",
    "            ft = np.array(self.feature_types*sub_X.shape[1])\n",
    "        else:\n",
    "            ft = self.feature_types\n",
    "            \n",
    "        feature_best, threshold_best, gini_best, split = None, None, None, None\n",
    "        for feature in range(0, sub_X.shape[1]):\n",
    "            feature_type = ft[feature]\n",
    "            categories_map = {}\n",
    "\n",
    "            if feature_type == \"real\":\n",
    "                feature_vector = sub_X[:, feature]\n",
    "            elif feature_type == \"categorical\":\n",
    "                counts = Counter(sub_X[:, feature])\n",
    "                clicks = Counter(sub_X[sub_y == 1, feature])\n",
    "                ratio = {}\n",
    "                for key, current_count in counts.items():\n",
    "                    if key in clicks:\n",
    "                        current_click = clicks[key]\n",
    "                    else:\n",
    "                        current_click = 0\n",
    "                    ratio[key] = current_click/current_count\n",
    "                sorted_categories = list(map(lambda x: x[0],\n",
    "                                             sorted(ratio.items(),\n",
    "                                                    key=lambda x: x[1])))\n",
    "                categories_map = dict(zip(sorted_categories,\n",
    "                                          list(range(len(sorted_categories)))))\n",
    "\n",
    "                feature_vector = np.array(list(map(lambda x: categories_map[x], sub_X[:, feature])))\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            if len(feature_vector) == 0:\n",
    "                continue\n",
    "\n",
    "            _, _, threshold, gini = find_best_split(feature_vector, np.array(sub_y))\n",
    "            if gini_best is None or gini > gini_best:\n",
    "                feature_best = feature\n",
    "                gini_best = gini\n",
    "                split = feature_vector < threshold\n",
    "\n",
    "                if feature_type == \"real\":\n",
    "                    threshold_best = threshold\n",
    "                elif feature_type == \"categorical\":\n",
    "                    threshold_best = list(map(lambda x: x[0],\n",
    "                                              filter(lambda x: x[1] < threshold,\n",
    "                                                     categories_map.items())))\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "        if gini_best == -1:\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = Counter(sub_y).most_common(1)[0][0]\n",
    "            return\n",
    "\n",
    "        if feature_best is None:\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = Counter(sub_y).most_common(1)[0][0]\n",
    "            return\n",
    "\n",
    "        node[\"type\"] = \"nonterminal\"\n",
    "\n",
    "        node[\"feature_split\"] = feature_best\n",
    "        if ft[feature_best] == \"real\":\n",
    "            node[\"threshold\"] = threshold_best\n",
    "        elif ft[feature_best] == \"categorical\":\n",
    "            node[\"categories_split\"] = threshold_best\n",
    "        else:\n",
    "            raise ValueError\n",
    "        node[\"left_child\"], node[\"right_child\"] = {}, {}\n",
    "        self._fit_node(sub_X[split], sub_y[split], node[\"left_child\"])\n",
    "        self._fit_node(sub_X[np.logical_not(split)],\n",
    "                       sub_y[np.logical_not(split)], node[\"right_child\"])\n",
    "\n",
    "    def _predict_node(self, x, node):\n",
    "        \n",
    "        if len(self.feature_types) == 1:\n",
    "            ft = np.array(self.feature_types*len(x))\n",
    "        else:\n",
    "            ft = self.feature_types\n",
    "            \n",
    "        x = np.array(x)\n",
    "        tree = node\n",
    "        class_i = None\n",
    "        for i in range(100):\n",
    "            if tree['type'] == 'terminal':\n",
    "                class_i = tree['class']\n",
    "                break\n",
    "            else:\n",
    "                feature_split_i = tree['feature_split']\n",
    "                if ft[tree['feature_split']] == 'real':\n",
    "                    real_split_i = tree['threshold']\n",
    "                    if x[feature_split_i] < real_split_i:\n",
    "                        tree = tree['left_child']\n",
    "                    else:\n",
    "                        tree = tree['right_child']\n",
    "                else:\n",
    "                    categories_split_i = tree['categories_split']\n",
    "                    if x[feature_split_i] in categories_split_i:\n",
    "                        tree = tree['left_child']\n",
    "                    else:\n",
    "                        tree = tree['right_child']\n",
    "        return class_i\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._fit_node(X, y, self._tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted = []\n",
    "        for x in X:\n",
    "            predicted.append(self._predict_node(x, self._tree))\n",
    "        return np.array(predicted)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
